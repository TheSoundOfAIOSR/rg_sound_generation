{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_harmonic_dataset_demo_amit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0fVn8yUJl_v"
      },
      "source": [
        "## Setup Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTjJuD9AmeYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1765f6fc-e628-4b45-fee4-3b57d0f1c733"
      },
      "source": [
        "import os\n",
        "from google.colab import files, drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dDJO8aq7PG3"
      },
      "source": [
        "### Access Harmonic NSynth Guitar Subset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NIEyEX3YXvH"
      },
      "source": [
        "dataset_dir = '/content/drive/My Drive/new_data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn7CQ4GQizHy"
      },
      "source": [
        "## Install Dependencies\n",
        "\n",
        "First we install the required dependencies with `pip`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjhdKFJbvRVU"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install -qU ddsp[data_preparation]==1.0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvvEoYX0GXDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b62ce3-44eb-4f95-b054-a6d558ba8f60"
      },
      "source": [
        "pip install git+https://github.com/fabiodimarco/tf-spectral-modeling-synthesis.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/fabiodimarco/tf-spectral-modeling-synthesis.git\n",
            "  Cloning https://github.com/fabiodimarco/tf-spectral-modeling-synthesis.git to /tmp/pip-req-build-jp1a296s\n",
            "  Running command git clone -q https://github.com/fabiodimarco/tf-spectral-modeling-synthesis.git /tmp/pip-req-build-jp1a296s\n",
            "Requirement already satisfied (use --upgrade to upgrade): tsms==0.0.1 from git+https://github.com/fabiodimarco/tf-spectral-modeling-synthesis.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from tsms==0.0.1) (2.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tsms==0.0.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (3.7.4.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (0.12.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (1.12)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (1.6.3)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (1.34.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (0.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (2.5.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (3.12.4)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (1.12.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (0.36.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (2.5.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tsms==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->tsms==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->tsms==0.0.1) (1.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->tsms==0.0.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->tsms==0.0.1) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->tsms==0.0.1) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->tsms==0.0.1) (57.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->tsms==0.0.1) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->tsms==0.0.1) (2.23.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->tsms==0.0.1) (1.5.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->tsms==0.0.1) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->tsms==0.0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->tsms==0.0.1) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->tsms==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->tsms==0.0.1) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->tsms==0.0.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->tsms==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->tsms==0.0.1) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->tsms==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->tsms==0.0.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->tsms==0.0.1) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow->tsms==0.0.1) (3.4.1)\n",
            "Building wheels for collected packages: tsms\n",
            "  Building wheel for tsms (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tsms: filename=tsms-0.0.1-cp37-none-any.whl size=10497 sha256=fc5a9602071b05d8a57fa2dccf7687cecc1b9d360eff0005803b1ba110b26919\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q_tr9z88/wheels/6f/31/3b/a01e898e4e31b4151712a4c8f139310b8cc2f1eb69f4326291\n",
            "Successfully built tsms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F46hAktqVQt8"
      },
      "source": [
        "import tensorflow as tf\n",
        "import ddsp.training.data as data\n",
        "import tsms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9AWf8NpBiB4"
      },
      "source": [
        "## Define DataProvider class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB0sWNuRoW4I"
      },
      "source": [
        "class CompleteTFRecordProvider(data.RecordProvider):\n",
        "    def __init__(self,\n",
        "                 file_pattern=None,\n",
        "                 example_secs=4,\n",
        "                 sample_rate=16000,\n",
        "                 frame_rate=250,\n",
        "                 map_func=None):\n",
        "        super().__init__(file_pattern, example_secs, sample_rate,\n",
        "                         frame_rate, tf.data.TFRecordDataset)\n",
        "        self._map_func = map_func\n",
        "\n",
        "    def get_dataset(self, shuffle=True):\n",
        "      def parse_tfexample(record):\n",
        "        features = tf.io.parse_single_example(record, self.features_dict)\n",
        "        if self._map_func is not None:\n",
        "          return self._map_func(features)\n",
        "        else:\n",
        "          return features\n",
        "\n",
        "      filenames = tf.data.Dataset.list_files(self._file_pattern, shuffle=shuffle)\n",
        "      dataset = filenames.interleave(\n",
        "          map_func=self._data_format_map_fn,\n",
        "          cycle_length=40,\n",
        "          num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
        "          deterministic=True)\n",
        "      dataset = dataset.map(parse_tfexample,\n",
        "                            num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
        "                            deterministic=True)\n",
        "      return dataset\n",
        "\n",
        "    @property\n",
        "    def features_dict(self):\n",
        "        return {\n",
        "            'sample_name': tf.io.FixedLenFeature([1], dtype=tf.string),\n",
        "            'instrument_id': tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "            'note_number': tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "            'velocity': tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "            'instrument_source': tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "            'qualities': tf.io.FixedLenFeature([10], dtype=tf.int64),\n",
        "            'audio': tf.io.FixedLenFeature([self._audio_length], dtype=tf.float32),\n",
        "            'f0_hz': tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "            'f0_confidence': tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "            'loudness_db': tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "            'f0_scaled': tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "            'ld_scaled': tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "            'z': tf.io.FixedLenFeature([self._feature_length * 16], dtype=tf.float32),\n",
        "            'f0_estimate': tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "            'h_freq': tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "            'h_mag': tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "            'h_phase': tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbUpwtyRB8wV"
      },
      "source": [
        "\n",
        "## Features Map\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbXhqrZaB5rw"
      },
      "source": [
        "def features_map(features):\n",
        "    sample_name = features['sample_name']\n",
        "    instrument_id = features['instrument_id']\n",
        "    note_number = features['note_number']\n",
        "    velocity = features['velocity']\n",
        "    instrument_source = features['instrument_source']\n",
        "    qualities = features['qualities']\n",
        "    audio = features['audio']\n",
        "    f0_hz = features['f0_hz']\n",
        "    f0_confidence = features['f0_confidence']\n",
        "    loudness_db = features['loudness_db']\n",
        "    f0_estimate = features['f0_estimate']\n",
        "    h_freq = features['h_freq']\n",
        "    h_mag = features['h_mag']\n",
        "    h_phase = features['h_phase']\n",
        "\n",
        "    f0_estimate = tf.io.parse_tensor(f0_estimate, out_type=tf.string)\n",
        "    h_freq = tf.io.parse_tensor(h_freq, out_type=tf.string)\n",
        "    h_mag = tf.io.parse_tensor(h_mag, out_type=tf.string)\n",
        "    h_phase = tf.io.parse_tensor(h_phase, out_type=tf.string)\n",
        "\n",
        "    f0_estimate = tf.io.parse_tensor(f0_estimate, out_type=tf.float32)\n",
        "    h_freq = tf.io.parse_tensor(h_freq, out_type=tf.float32)\n",
        "    h_mag = tf.io.parse_tensor(h_mag, out_type=tf.float32)\n",
        "    h_phase = tf.io.parse_tensor(h_phase, out_type=tf.float32)\n",
        "\n",
        "    h_freq = tf.expand_dims(h_freq, axis=0)\n",
        "    h_mag = tf.expand_dims(h_mag, axis=0)\n",
        "    h_phase = tf.expand_dims(h_phase, axis=0)\n",
        "\n",
        "    f0 = tsms.core.harmonic_analysis_to_f0(h_freq, h_mag)\n",
        "    f0_mean = tf.math.reduce_mean(f0, axis=1)\n",
        "    harmonics = tf.shape(h_freq)[-1]\n",
        "    harmonic_indices = tf.range(1, harmonics + 1, dtype=tf.float32)\n",
        "    harmonic_indices = harmonic_indices[tf.newaxis, tf.newaxis, :]\n",
        "    h_freq_centered = h_freq - (f0_mean * harmonic_indices)\n",
        "    g_phase = tsms.core.generate_phase(h_freq, sample_rate=16000, frame_step=64)\n",
        "    d_phase = tsms.core.phase_diff(h_phase, g_phase)\n",
        "    # unwrap d_phase from +/- pi to +/- 2*pi\n",
        "    d_phase = tsms.core.phase_unwrap(d_phase, axis=1)\n",
        "    d_phase = (d_phase + 2.0 * np.pi) % (4.0 * np.pi) - 2.0 * np.pi\n",
        "\n",
        "    h_freq = tf.squeeze(h_freq, axis=0)\n",
        "    h_mag = tf.squeeze(h_mag, axis=0)\n",
        "    h_phase = tf.squeeze(h_phase, axis=0)\n",
        "    h_freq_centered = tf.squeeze(h_freq_centered, axis=0)\n",
        "    d_phase = tf.squeeze(d_phase, axis=0)\n",
        "\n",
        "    h_freq_norm = (h_freq_centered - tf.reduce_mean(h_freq_centered)) / tf.math.reduce_std(h_freq_centered)\n",
        "    h_mag_norm = (h_mag - tf.reduce_mean(h_mag)) / tf.math.reduce_std(h_mag)\n",
        "    d_phase_norm = (d_phase - tf.reduce_mean(d_phase)) / tf.math.reduce_std(d_phase)\n",
        "\n",
        "    element_dict = {\n",
        "        'sample_name': sample_name,\n",
        "        'instrument_id': instrument_id,\n",
        "        'note_number': note_number,\n",
        "        'velocity': velocity,\n",
        "        'h_freq': h_freq,\n",
        "        'h_mag': h_mag,\n",
        "        'h_phase': h_phase,\n",
        "        'd_phase': d_phase,\n",
        "        'h_freq_centered': h_freq_centered,\n",
        "        'h_freq_norm': h_freq_norm,\n",
        "        'h_mag_norm': h_mag_norm,\n",
        "        'd_phase_norm': d_phase_norm\n",
        "    }\n",
        "    return element_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7dYOU811Ni4"
      },
      "source": [
        "## Create datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Md-jyDOvxj"
      },
      "source": [
        "train_tfrecord_file = os.path.join(dataset_dir, 'train.tfrecord')\n",
        "valid_tfrecord_file = os.path.join(dataset_dir, 'valid.tfrecord')\n",
        "test_tfrecord_file = os.path.join(dataset_dir, 'test.tfrecord')\n",
        "\n",
        "example_secs = 4\n",
        "sample_rate = 16000\n",
        "frame_rate = 250\n",
        "\n",
        "# Create train dataset\n",
        "train_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=train_tfrecord_file,\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "train_dataset = train_data_provider.get_dataset(shuffle=False) \n",
        "\n",
        "# Create valid dataset\n",
        "valid_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=valid_tfrecord_file,\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "valid_dataset = valid_data_provider.get_dataset(shuffle=False) \n",
        "\n",
        "# Create test dataset\n",
        "test_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=test_tfrecord_file,\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "test_dataset = test_data_provider.get_dataset(shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbWJxadU1DKA"
      },
      "source": [
        "## Filter datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxWIVnorGdzY"
      },
      "source": [
        "def conditioning_function(sample):\n",
        "    return sample['note_number'], sample['instrument_id'], sample['velocity']\n",
        "\n",
        "def return_conditioning(dataset):\n",
        "    return dataset.map(lambda x: conditioning_function(x),\n",
        "                       num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
        "                       deterministic=True)\n",
        "\n",
        "def pad_function(sample):\n",
        "    return tf.pad(sample, \n",
        "                  tf.convert_to_tensor([[0,0], [0, 130 - tf.shape(sample)[1]]]))\n",
        "    \n",
        "\n",
        "def pad_dataset(dataset):\n",
        "    return dataset.map(lambda x: pad_function(x),\n",
        "                       num_parallel_calls=tf.data.experimental.AUTOTUNE, \n",
        "                       deterministic=True)\n",
        "    \n",
        "def filter_instruments(sample):\n",
        "    banned_ids = tf.constant([6,11,13,19,23,25,30,48,49,51,64,71,79,80,82,90,92])\n",
        "    instrument_id = sample['instrument_id']\n",
        "    isbanned = tf.equal(banned_ids, tf.cast(instrument_id, banned_ids.dtype))\n",
        "    reduced = tf.reduce_sum(tf.cast(isbanned, tf.float32))\n",
        "    return tf.equal(reduced, tf.constant(0.))\n",
        "\n",
        "def filter_pitches(sample):\n",
        "    pitches=tf.constant([x for x in range(40,89)])\n",
        "    note_number = sample['note_number']\n",
        "    isvalid = tf.equal(pitches, tf.cast(note_number, pitches.dtype))\n",
        "    reduced = tf.reduce_sum(tf.cast(isvalid, tf.float32))\n",
        "    return tf.greater(reduced, tf.constant(0.))\n",
        "\n",
        "def input_preprocessing(dataset):\n",
        "    dataset_filter = dataset.filter(filter_instruments).filter(filter_pitches)\n",
        "\n",
        "    h_freq_centered = dataset_filter.map(lambda x: x['h_freq_centered'])\n",
        "    h_mag = dataset_filter.map(lambda x: x['h_mag'])\n",
        "    d_phase = dataset_filter.map(lambda x: x['d_phase'])\n",
        "    h_freq_norm = dataset_filter.map(lambda x: x['h_freq_norm'])\n",
        "    h_mag_norm = dataset_filter.map(lambda x: x['h_mag_norm'])\n",
        "    d_phase_norm = dataset_filter.map(lambda x: x['d_phase_norm'])\n",
        "\n",
        "    h_freq_pad = pad_dataset(h_freq_centered)\n",
        "    h_mag_pad = pad_dataset(h_mag)\n",
        "    d_phase_pad = pad_dataset(d_phase)\n",
        "    h_freq_norm_pad = pad_dataset(h_freq_norm)\n",
        "    h_mag_norm_pad = pad_dataset(h_mag_norm)\n",
        "    d_phase_norm_pad = pad_dataset(d_phase_norm)\n",
        "\n",
        "    conditioning_dataset = return_conditioning(dataset_filter)\n",
        "\n",
        "    return tf.data.Dataset.zip((h_freq_norm_pad, h_mag_norm_pad, d_phase_norm_pad, \n",
        "                                h_freq_pad, h_mag_pad, d_phase_pad, \n",
        "                                conditioning_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIOYM9d6Cqrg"
      },
      "source": [
        "X_train = input_preprocessing(train_dataset)\n",
        "X_valid = input_preprocessing(valid_dataset)\n",
        "X_test = input_preprocessing(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW_KL_bHv3fL"
      },
      "source": [
        "## Build VAE Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_z5C3q5TRPI"
      },
      "source": [
        "class Sampling(layers.Layer):\n",
        "  \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding the input.\"\"\"\n",
        "\n",
        "  def call(self, inputs):\n",
        "      z_mean, z_log_var = inputs\n",
        "      batch = tf.shape(z_mean)[0]\n",
        "      dim = tf.shape(z_mean)[1]\n",
        "      epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "      return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x = tf.reshape(tf.transpose(tf.stack(data[:3], axis=0), perm=[1, 2, 0]), [-1,1001,130,3])\n",
        "        y = tf.reshape(tf.transpose(tf.stack(data[3:6], axis=0), perm=[1, 2, 0]), [-1,1001,130,3])\n",
        "        conditioning = data[6]\n",
        "        pitch = conditioning[0]\n",
        "        instrument = conditioning[1]\n",
        "        velocity = conditioning[2]\n",
        "        mag = data[4]\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(x)\n",
        "            reconstruction = self.decoder([z, pitch, instrument, velocity]) #qualities\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    tf.math.multiply(\n",
        "                        keras.losses.mean_squared_error(y, reconstruction), \n",
        "                        mag), \n",
        "                    axis=(1,2))\n",
        "                )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuzZPn8Ys0iX"
      },
      "source": [
        "def build_encoder(latent_dim, lstm_dim, units=[32,32,64,64], kernel_sizes=[3,3,3,3], strides=[2,2,2,2]):\n",
        "    encoder_inputs = keras.Input(shape=(1001, 130, 3))\n",
        "    for i, (unit, kernel_size, stride) in enumerate(zip(units,kernel_sizes,strides)):\n",
        "        if i == 0:\n",
        "            x = layers.Conv2D(unit, (kernel_size), activation=\"relu\", strides=(stride), padding=\"same\")(encoder_inputs)\n",
        "        else:\n",
        "            x = layers.Conv2D(unit, (kernel_size), activation=\"relu\", strides=(stride), padding=\"same\")(x)\n",
        "    x = layers.TimeDistributed(layers.Flatten())(x)\n",
        "    # x = layers.TimeDistributed(layers.Dense(lstm_dim, activation=\"relu\"))(x)\n",
        "    # x = layers.Bidirectional(layers.LSTM(lstm_dim, activation=\"tanh\", return_sequences=True, dropout=0.1))(x) \n",
        "    x = layers.LSTM(lstm_dim, activation=\"relu\", return_sequences=False, dropout=0.1)(x)\n",
        "    z_mean = layers.Dense(latent_dim, activation=\"relu\", name=\"z_mean\")(x)\n",
        "    z_log_var = layers.Dense(latent_dim, activation=\"relu\", name=\"z_log_var\")(x)\n",
        "    z = Sampling()([z_mean, z_log_var])\n",
        "    encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "    encoder.summary()\n",
        "    \n",
        "    return encoder\n",
        "\n",
        "def _conv_shape(strides, dim_size=[1001, 130, 3]):\n",
        "    for i in strides:\n",
        "        dim_size = [math.ceil(x / i) for x in dim_size]\n",
        "    return dim_size\n",
        "\n",
        "def build_decoder(latent_dim, lstm_dim, units=[32,32,64,64], kernel_sizes=[3,3,3,3], strides=[2,2,2,2]):\n",
        "    conv_shape = _conv_shape(strides)\n",
        "    units.reverse()\n",
        "    kernel_sizes.reverse()\n",
        "    strides.reverse()\n",
        "\n",
        "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "    pitch_inputs = keras.Input(shape=(1,))\n",
        "    instrument_inputs = keras.Input(shape=(1,))\n",
        "    velocity_inputs = keras.Input(shape=(1,))\n",
        "    \n",
        "    pitch_embeddings = layers.Flatten()(layers.Embedding(128, 64, input_length=1, name=\"pitch_emb\")(pitch_inputs))\n",
        "    instrument_embeddings = layers.Flatten()(layers.Embedding(97, 8, input_length=1, name=\"instrument_emb\")(instrument_inputs))\n",
        "    velocity_embeddings = layers.Flatten()(layers.Embedding(128, 4, input_length=1, name=\"vel_emb\")(velocity_inputs))\n",
        "\n",
        "    x = tf.keras.layers.Concatenate(axis=1)([latent_inputs, pitch_embeddings, \n",
        "                                                  instrument_embeddings, velocity_embeddings]) \n",
        "    # x = layers.Dense(lstm_dim, activation=\"relu\")(x)\n",
        "    x = layers.RepeatVector(conv_shape[0])(x)\n",
        "    x = layers.LSTM(lstm_dim, activation=\"relu\", return_sequences=True, dropout=0.1)(x)\n",
        "    # x = layers.Bidirectional(layers.LSTM(lstm_dim, activation=\"tanh\", return_sequences=True, dropout=0.1))(x) \n",
        "    # x = layers.TimeDistributed(layers.Dense(conv_shape[1] * units[0], activation=\"relu\"))(x)\n",
        "    x = layers.Reshape((conv_shape[0], conv_shape[1], int(x.shape[2]/conv_shape[1])))(x) \n",
        "    for i, (unit, kernel_size, stride) in enumerate(zip(units,kernel_sizes,strides)): \n",
        "        x = layers.Conv2DTranspose(unit, (kernel_size), activation=\"relu\", strides=(stride), padding=\"same\")(x)\n",
        "    x = layers.Cropping2D(cropping=((3, 4), (7, 7)))(x)\n",
        "    decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"linear\", padding=\"same\")(x)\n",
        "    decoder = keras.Model([latent_inputs, pitch_inputs, \n",
        "                           instrument_inputs, velocity_inputs], \n",
        "                          decoder_outputs, name=\"decoder\") \n",
        "    decoder.summary()\n",
        "    \n",
        "    return decoder\n",
        "\n",
        "def build_vae(latent_dim, lstm_dim, learning_rate=0.001, units=[32,32,64,64], kernel_sizes=[3,3,3,3], strides=[2,2,2,2]):\n",
        "    encoder = build_encoder(latent_dim, lstm_dim, units, kernel_sizes, strides)\n",
        "    decoder = build_decoder(latent_dim, lstm_dim, units, kernel_sizes, strides)\n",
        "    vae = VAE(encoder, decoder)\n",
        "    vae.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate))    \n",
        "    return vae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80D5Czt4vf0M",
        "outputId": "f04bce42-87a7-4ad6-849b-8cd8a74083d5"
      },
      "source": [
        "vae = build_vae(latent_dim = 128, lstm_dim = 128, learning_rate = 0.001, \n",
        "                units = [64,64,128,128,128,128], kernel_sizes = [7,7,5,5,5,5], strides = [3,3,2,2,2,2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 1001, 130, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 334, 44, 64)  9472        input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 112, 15, 64)  200768      conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 56, 8, 128)   204928      conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 28, 4, 128)   409728      conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 14, 2, 128)   409728      conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 7, 1, 128)    409728      conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 7, 128)       0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 128)          131584      time_distributed_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 128)          16512       lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "z_log_var (Dense)               (None, 128)          16512       lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "sampling_2 (Sampling)           (None, 128)          0           z_mean[0][0]                     \n",
            "                                                                 z_log_var[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,808,960\n",
            "Trainable params: 1,808,960\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_15 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "pitch_emb (Embedding)           (None, 1, 64)        8192        input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "instrument_emb (Embedding)      (None, 1, 8)         776         input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "vel_emb (Embedding)             (None, 1, 4)         512         input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_8 (Flatten)             (None, 64)           0           pitch_emb[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_9 (Flatten)             (None, 8)            0           instrument_emb[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_10 (Flatten)            (None, 4)            0           vel_emb[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 204)          0           input_12[0][0]                   \n",
            "                                                                 flatten_8[0][0]                  \n",
            "                                                                 flatten_9[0][0]                  \n",
            "                                                                 flatten_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_1 (RepeatVector)  (None, 7, 204)       0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   (None, 7, 128)       170496      repeat_vector_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 7, 1, 128)    0           lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 14, 2, 128)   409728      reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_8 (Conv2DTrans (None, 28, 4, 128)   409728      conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_9 (Conv2DTrans (None, 56, 8, 128)   409728      conv2d_transpose_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_10 (Conv2DTran (None, 112, 16, 128) 409728      conv2d_transpose_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_11 (Conv2DTran (None, 336, 48, 64)  401472      conv2d_transpose_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_12 (Conv2DTran (None, 1008, 144, 64 200768      conv2d_transpose_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "cropping2d_1 (Cropping2D)       (None, 1001, 130, 64 0           conv2d_transpose_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_13 (Conv2DTran (None, 1001, 130, 3) 1731        cropping2d_1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 2,422,859\n",
            "Trainable params: 2,422,859\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaSoJenHyRZI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "3f6fe9ca-b4b2-4782-ec72-5424d8861170"
      },
      "source": [
        "vae.fit(x=X_train, epochs=5, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "   1981/Unknown - 2307s 1s/step - loss: nan - reconstruction_loss: nan - kl_loss: nan"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-7a3b71b35095>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM1f9edPwZB4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}