{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mapping_Network_TCN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEO2FZbVMl4O"
      },
      "source": [
        "# Purpose\n",
        "This notebook is used to map note_number, velocity, instrument_source, qualities, z to f0_scaled and ld_scaled. It is composed of a LSTM layer, GRU layer and  a dense layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byQTezEBbNRA"
      },
      "source": [
        "# Setup google drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seiaz41x00S_",
        "outputId": "1cac65ab-7931-4cd7-fa1b-53693412e8bb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ3HJu7_5cMK",
        "outputId": "c43ee3a1-f4c4-495a-cf12-6e7b1894a9b8"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install -qU ddsp[data_preparation]==1.0.1\n",
        "!pip install keras-tcn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 174kB 5.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 5.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 7.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6MB 36.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 9.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.0MB 5.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6MB 21.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 378kB 38.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 17.7MB 205kB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 41.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 42.9MB/s \n",
            "\u001b[?25h  Building wheel for cloudml-hypertune (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for crepe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: apache-beam 2.28.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.28.0 has requirement dill<0.3.2,>=0.3.1.1, but you'll have dill 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.28.0 has requirement future<1.0.0,>=0.18.2, but you'll have future 0.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.28.0 has requirement requests<3.0.0,>=2.24.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "Collecting keras-tcn\n",
            "  Downloading https://files.pythonhosted.org/packages/84/31/579d2dccda0a7d5ef5839b3f73257a5209dffafd319f6d1cebb16007d3fc/keras_tcn-3.4.0-py2.py3-none-any.whl\n",
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\u001b[K     |████████████████████████████████| 706kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tcn) (1.19.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-tcn) (2.4.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->keras-tcn) (2.7.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.4.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.12)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.32.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.6.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.10.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.12.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.12.4)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.3.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.7.4.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->keras-tcn) (0.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->keras-tcn) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->keras-tcn) (1.28.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->keras-tcn) (54.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->keras-tcn) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->keras-tcn) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->keras-tcn) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->keras-tcn) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->keras-tcn) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->keras-tcn) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->keras-tcn) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->keras-tcn) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras-tcn) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras-tcn) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras-tcn) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras-tcn) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->keras-tcn) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->keras-tcn) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow->keras-tcn) (3.4.1)\n",
            "Installing collected packages: tensorflow-addons, keras-tcn\n",
            "Successfully installed keras-tcn-3.4.0 tensorflow-addons-0.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27LKzcK5d4ft"
      },
      "source": [
        "# Make directories to save model and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OspCTcni6bYE",
        "outputId": "4edb260a-943e-4157-ba41-be26091471a5"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "from tcn import TCN, tcn_full_summary\n",
        "\n",
        "drive_dir = '/content/drive/My Drive/Sound_generation'\n",
        "checkpoint_dir = os.path.join(drive_dir, 'mapping/checkpoint')\n",
        "\n",
        "assert os.path.exists(drive_dir)\n",
        "print('Drive Directory Exists:', drive_dir)\n",
        "\n",
        "!mkdir -p \"$checkpoint_dir\"\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive Directory Exists: /content/drive/My Drive/Sound_generation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlucbB8Hd27v"
      },
      "source": [
        "# Download Complete NSynth Guitar Subse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW2CmoR77k0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3becb123-c1c0-40fc-9bf3-2d43661a2dca"
      },
      "source": [
        "dataset_dir = '/content/complete'\n",
        "train_dataset_dir = os.path.join(dataset_dir, 'train')\n",
        "valid_dataset_dir = os.path.join(dataset_dir, 'valid')\n",
        "test_dataset_dir = os.path.join(dataset_dir, 'test')\n",
        "\n",
        "train_tfrecord_file = os.path.join(train_dataset_dir, 'complete.tfrecord')\n",
        "valid_tfrecord_file = os.path.join(valid_dataset_dir, 'complete.tfrecord')\n",
        "test_tfrecord_file = os.path.join(test_dataset_dir, 'complete.tfrecord')\n",
        "\n",
        "if not os.path.exists(dataset_dir):\n",
        "  train = 'https://osr-tsoai.s3.amazonaws.com/complete/train/complete.tfrecord'\n",
        "  valid = 'https://osr-tsoai.s3.amazonaws.com/complete/valid/complete.tfrecord'\n",
        "  test = 'https://osr-tsoai.s3.amazonaws.com/complete/test/complete.tfrecord'\n",
        "\n",
        "  print(\"Downloading train dataset to {}\\n\".format(train_dataset_dir))\n",
        "  !mkdir -p \"$train_dataset_dir\"\n",
        "  !curl $train --output $train_tfrecord_file\n",
        "\n",
        "  print(\"\\nDownloading valid dataset to {}\\n\".format(valid_dataset_dir))\n",
        "  !mkdir -p \"$valid_dataset_dir\"\n",
        "  !curl $valid --output $valid_tfrecord_file\n",
        "\n",
        "  print(\"\\nDownloading test dataset to {}\\n\".format(test_dataset_dir))\n",
        "  !mkdir -p \"$test_dataset_dir\"\n",
        "  !curl $test --output $test_tfrecord_file"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train dataset to /content/complete/train\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 10.3G  100 10.3G    0     0  16.2M      0  0:10:53  0:10:53 --:--:-- 16.5M\n",
            "\n",
            "Downloading valid dataset to /content/complete/valid\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  675M  100  675M    0     0  15.3M      0  0:00:43  0:00:43 --:--:-- 15.1M\n",
            "\n",
            "Downloading test dataset to /content/complete/test\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  211M  100  211M    0     0  13.5M      0  0:00:15  0:00:15 --:--:-- 16.0M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGVn7_Y7e7_O"
      },
      "source": [
        "# Copying data to drive or from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuYlkUcDdyAa"
      },
      "source": [
        "# !cp -r  /content/drive/MyDrive/Sound_generation/mapping/complete  ./"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFaepHvehLXC"
      },
      "source": [
        "# Defining Data class provider\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVqYQLJNgCdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f30d94-a15a-4cd6-f5f5-1b0c95ce24e4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import ddsp.training.data as data\n",
        "\n",
        "class CompleteTFRecordProvider(data.RecordProvider):\n",
        "  def __init__(self,\n",
        "               file_pattern=None,\n",
        "               example_secs=4,\n",
        "               sample_rate=16000,\n",
        "               frame_rate=250,\n",
        "               map_func=None):\n",
        "    super().__init__(file_pattern, example_secs, sample_rate,\n",
        "                      frame_rate, tf.data.TFRecordDataset)\n",
        "    self._map_func = map_func\n",
        "\n",
        "  def get_dataset(self, shuffle=True):\n",
        "    def parse_tfexample(record):\n",
        "      features = tf.io.parse_single_example(record, self.features_dict)\n",
        "      if self._map_func is not None:\n",
        "        return self._map_func(features)\n",
        "      else:\n",
        "        return features\n",
        "\n",
        "    filenames = tf.data.Dataset.list_files(self._file_pattern, shuffle=shuffle)\n",
        "    dataset = filenames.interleave(\n",
        "        map_func=self._data_format_map_fn,\n",
        "        cycle_length=40,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.map(parse_tfexample,\n",
        "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "  @property\n",
        "  def features_dict(self):\n",
        "    return {\n",
        "      'sample_name':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.string),\n",
        "      'note_number':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'velocity':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'instrument_source':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'qualities':\n",
        "        tf.io.FixedLenFeature([10], dtype=tf.int64),\n",
        "      'audio':\n",
        "        tf.io.FixedLenFeature([self._audio_length], dtype=tf.float32),\n",
        "      'f0_hz':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'f0_confidence':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'loudness_db':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'f0_scaled':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'ld_scaled':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'z':\n",
        "        tf.io.FixedLenFeature([self._feature_length * 16], dtype=tf.float32),\n",
        "    }\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Argument whitelist is deprecated. Please use allowlist.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyLOqJNBhwa-"
      },
      "source": [
        "# Defining feature mapping function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJlzNevzhyul"
      },
      "source": [
        "def features_map(features):\n",
        "  note_number = features['note_number']\n",
        "  velocity = features['velocity']\n",
        "  instrument_source = features['instrument_source']\n",
        "  qualities = features['qualities']\n",
        "  f0_scaled = features['f0_scaled']\n",
        "  ld_scaled = features['ld_scaled']\n",
        "  z = features['z']\n",
        "\n",
        "  sequence_length = f0_scaled.shape[0]\n",
        "\n",
        "  def convert_to_sequence(feature):\n",
        "    channels = feature.shape[0]\n",
        "    feature = tf.expand_dims(feature, axis=0)\n",
        "\n",
        "    feature = tf.broadcast_to(feature, shape=(sequence_length, channels))\n",
        "    feature = tf.cast(feature, dtype=tf.float32)\n",
        "    \n",
        "    return feature\n",
        "\n",
        "  # Normalize data\n",
        "  # 0-127\n",
        "  note_number = note_number / 127\n",
        "  velocity = velocity / 127\n",
        "\n",
        "  # 0-2\n",
        "  # 0\tacoustic, 1\telectronic, 2\tsynthetic\n",
        "  instrument_source = instrument_source / 2\n",
        "\n",
        "  # Prepare dataset for a sequence to sequence mapping\n",
        "  note_number = convert_to_sequence(note_number)\n",
        "  velocity = convert_to_sequence(velocity)\n",
        "  instrument_source = convert_to_sequence(instrument_source)\n",
        "  qualities = convert_to_sequence(qualities)\n",
        "\n",
        "  f0_scaled = tf.expand_dims(f0_scaled, axis=-1)\n",
        "  f0_variation = f0_scaled * 127.0 - tf.cast(note_number, dtype=tf.float32)\n",
        "  f0_variation = tf.clip_by_value(f0_variation, -1.0, 1.0)\n",
        "  #f0_variation = tf.expand_dims(f0_variation, axis=-1)\n",
        "\n",
        "  ld_scaled = tf.expand_dims(ld_scaled, axis=-1)\n",
        "  z = tf.reshape(z, shape=(sequence_length, 16))\n",
        "\n",
        "  input = tf.concat(\n",
        "      [note_number, velocity, instrument_source, qualities, z],\n",
        "      axis=-1)\n",
        "  \n",
        "  output = tf.concat(\n",
        "      [f0_variation, ld_scaled],\n",
        "      axis=-1)\n",
        "  # print(f'f0_variation shape: {f0_variation}' )\n",
        "  # print(f'f0_scaled shape: {f0_scaled}' )\n",
        "\n",
        "  return (input, output)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWeUD9z3nLAF"
      },
      "source": [
        "# Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crbnUBoxnMY3"
      },
      "source": [
        "batch_size = 16\n",
        "example_secs = 4\n",
        "sample_rate = 16000\n",
        "frame_rate = 250\n",
        "\n",
        "# Create train dataset\n",
        "train_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=train_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "train_dataset = train_data_provider.get_batch(\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    repeats=-1)\n",
        "\n",
        "# Create valid dataset\n",
        "valid_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=valid_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "valid_dataset = valid_data_provider.get_batch(\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    repeats=-1)\n",
        "\n",
        "# Create test dataset\n",
        "test_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=test_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "test_dataset = test_data_provider.get_batch(\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    repeats=-1)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI99UJes_RAd",
        "outputId": "f34641f0-f45c-4b5a-ea92-1ffac7809497"
      },
      "source": [
        "tcn_layer = TCN(input_shape=(1000, 29), return_sequences=True, nb_filters=64, kernel_size=8,nb_stacks=2)\n",
        "print('Receptive field size =', tcn_layer.receptive_field)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Receptive field size = 1765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00zdXuekoW0O"
      },
      "source": [
        "# Create and compile mapping model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm3KlXvunN1n"
      },
      "source": [
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                  tcn_layer,\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    tf.keras.layers.GRU(16, return_sequences=True),\n",
        "    tf.keras.layers.Dense(2, activation='tanh')\n",
        "])\n",
        "\n",
        "loss = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=loss,\n",
        "    metrics=[tf.keras.losses.MeanSquaredError()])\n",
        "\n",
        "log_dir = \"logs/fit/loudness_f0_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NG0o8Yzpvgf"
      },
      "source": [
        "# Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvuUYIkhprsc",
        "outputId": "71f935cf-fe18-4cc2-e40a-17b9ebeca439"
      },
      "source": [
        "x_train, y_train = next(iter(train_dataset))\n",
        "out = model(x_train)\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "tcn_2 (TCN)                  (None, 1000, 64)          771968    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1000, 32)          12416     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 1000, 16)          2400      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1000, 2)           34        \n",
            "=================================================================\n",
            "Total params: 786,818\n",
            "Trainable params: 786,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2esZxKsEqU_f"
      },
      "source": [
        "# Load checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KN7G6HFqWuR"
      },
      "source": [
        "checkpoint_file = os.path.join(checkpoint_dir, 'cp.ckpt')\n",
        "\n",
        "if os.path.isdir(checkpoint_dir) and os.listdir(checkpoint_dir):\n",
        "    model.load_weights(checkpoint_file)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_5Ytb13qkdf"
      },
      "source": [
        "# Create training callbacks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-W-3Q5tqXC8"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_file,\n",
        "    save_weights_only=True,\n",
        "    verbose=0,\n",
        "    save_freq='epoch')\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 10:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * 0.9\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhdPr24xquML"
      },
      "source": [
        "# Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFzj98-eqvTB",
        "outputId": "f880e85f-123d-4242-a85d-3836e1774c18"
      },
      "source": [
        "epochs = 100\n",
        "steps_per_epoch = 100\n",
        "validation_steps = 10\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model.fit(train_dataset,\n",
        "            epochs=epochs,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            validation_data=valid_dataset,\n",
        "            validation_steps=validation_steps,\n",
        "            callbacks=[lr_scheduler,tensorboard_callback,checkpoint])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 42s 352ms/step - loss: 0.1802 - mean_squared_error: 0.1802 - val_loss: 0.1722 - val_mean_squared_error: 0.1722\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1759 - mean_squared_error: 0.1759 - val_loss: 0.1708 - val_mean_squared_error: 0.1708\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1762 - mean_squared_error: 0.1762 - val_loss: 0.1698 - val_mean_squared_error: 0.1698\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1742 - mean_squared_error: 0.1742 - val_loss: 0.1689 - val_mean_squared_error: 0.1689\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1748 - mean_squared_error: 0.1748 - val_loss: 0.1680 - val_mean_squared_error: 0.1680\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 32s 323ms/step - loss: 0.1728 - mean_squared_error: 0.1728 - val_loss: 0.1673 - val_mean_squared_error: 0.1673\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1724 - mean_squared_error: 0.1724 - val_loss: 0.1666 - val_mean_squared_error: 0.1666\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1707 - mean_squared_error: 0.1707 - val_loss: 0.1659 - val_mean_squared_error: 0.1659\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1713 - mean_squared_error: 0.1713 - val_loss: 0.1653 - val_mean_squared_error: 0.1653\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1706 - mean_squared_error: 0.1706 - val_loss: 0.1647 - val_mean_squared_error: 0.1647\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1689 - mean_squared_error: 0.1689 - val_loss: 0.1642 - val_mean_squared_error: 0.1642\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1690 - mean_squared_error: 0.1690 - val_loss: 0.1637 - val_mean_squared_error: 0.1637\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1690 - mean_squared_error: 0.1690 - val_loss: 0.1633 - val_mean_squared_error: 0.1633\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1684 - mean_squared_error: 0.1684 - val_loss: 0.1629 - val_mean_squared_error: 0.1629\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1687 - mean_squared_error: 0.1687 - val_loss: 0.1626 - val_mean_squared_error: 0.1626\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1673 - mean_squared_error: 0.1673 - val_loss: 0.1623 - val_mean_squared_error: 0.1623\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1678 - mean_squared_error: 0.1678 - val_loss: 0.1621 - val_mean_squared_error: 0.1621\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1663 - mean_squared_error: 0.1663 - val_loss: 0.1619 - val_mean_squared_error: 0.1619\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1668 - mean_squared_error: 0.1668 - val_loss: 0.1617 - val_mean_squared_error: 0.1617\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1666 - mean_squared_error: 0.1666 - val_loss: 0.1615 - val_mean_squared_error: 0.1615\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1665 - mean_squared_error: 0.1665 - val_loss: 0.1613 - val_mean_squared_error: 0.1613\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1673 - mean_squared_error: 0.1673 - val_loss: 0.1612 - val_mean_squared_error: 0.1612\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1658 - mean_squared_error: 0.1658 - val_loss: 0.1611 - val_mean_squared_error: 0.1611\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1664 - mean_squared_error: 0.1664 - val_loss: 0.1610 - val_mean_squared_error: 0.1610\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1648 - mean_squared_error: 0.1648 - val_loss: 0.1609 - val_mean_squared_error: 0.1609\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1666 - mean_squared_error: 0.1666 - val_loss: 0.1608 - val_mean_squared_error: 0.1608\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1662 - mean_squared_error: 0.1662 - val_loss: 0.1607 - val_mean_squared_error: 0.1607\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1650 - mean_squared_error: 0.1650 - val_loss: 0.1606 - val_mean_squared_error: 0.1606\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1651 - mean_squared_error: 0.1651 - val_loss: 0.1605 - val_mean_squared_error: 0.1605\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1651 - mean_squared_error: 0.1651 - val_loss: 0.1605 - val_mean_squared_error: 0.1605\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1652 - mean_squared_error: 0.1652 - val_loss: 0.1604 - val_mean_squared_error: 0.1604\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1654 - mean_squared_error: 0.1654 - val_loss: 0.1604 - val_mean_squared_error: 0.1604\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1654 - mean_squared_error: 0.1654 - val_loss: 0.1603 - val_mean_squared_error: 0.1603\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1660 - mean_squared_error: 0.1660 - val_loss: 0.1603 - val_mean_squared_error: 0.1603\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1645 - mean_squared_error: 0.1645 - val_loss: 0.1603 - val_mean_squared_error: 0.1603\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1651 - mean_squared_error: 0.1651 - val_loss: 0.1602 - val_mean_squared_error: 0.1602\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 32s 323ms/step - loss: 0.1644 - mean_squared_error: 0.1644 - val_loss: 0.1602 - val_mean_squared_error: 0.1602\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1650 - mean_squared_error: 0.1650 - val_loss: 0.1602 - val_mean_squared_error: 0.1602\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1650 - mean_squared_error: 0.1650 - val_loss: 0.1602 - val_mean_squared_error: 0.1602\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1655 - mean_squared_error: 0.1655 - val_loss: 0.1601 - val_mean_squared_error: 0.1601\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1651 - mean_squared_error: 0.1651 - val_loss: 0.1601 - val_mean_squared_error: 0.1601\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1658 - mean_squared_error: 0.1658 - val_loss: 0.1601 - val_mean_squared_error: 0.1601\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1637 - mean_squared_error: 0.1637 - val_loss: 0.1601 - val_mean_squared_error: 0.1601\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1653 - mean_squared_error: 0.1653 - val_loss: 0.1601 - val_mean_squared_error: 0.1601\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1655 - mean_squared_error: 0.1655 - val_loss: 0.1601 - val_mean_squared_error: 0.1601\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1646 - mean_squared_error: 0.1646 - val_loss: 0.1601 - val_mean_squared_error: 0.1601\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1651 - mean_squared_error: 0.1651 - val_loss: 0.1601 - val_mean_squared_error: 0.1601\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1654 - mean_squared_error: 0.1654 - val_loss: 0.1601 - val_mean_squared_error: 0.1601\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1641 - mean_squared_error: 0.1641 - val_loss: 0.1601 - val_mean_squared_error: 0.1601\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1659 - mean_squared_error: 0.1659 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1648 - mean_squared_error: 0.1648 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1650 - mean_squared_error: 0.1650 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1646 - mean_squared_error: 0.1646 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1655 - mean_squared_error: 0.1655 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1650 - mean_squared_error: 0.1650 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1645 - mean_squared_error: 0.1645 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1653 - mean_squared_error: 0.1653 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1656 - mean_squared_error: 0.1656 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1645 - mean_squared_error: 0.1645 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1642 - mean_squared_error: 0.1642 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1650 - mean_squared_error: 0.1650 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1653 - mean_squared_error: 0.1653 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1650 - mean_squared_error: 0.1650 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1639 - mean_squared_error: 0.1639 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1657 - mean_squared_error: 0.1657 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1650 - mean_squared_error: 0.1650 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1649 - mean_squared_error: 0.1649 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1656 - mean_squared_error: 0.1656 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1637 - mean_squared_error: 0.1637 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1647 - mean_squared_error: 0.1647 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1658 - mean_squared_error: 0.1658 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1642 - mean_squared_error: 0.1642 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1644 - mean_squared_error: 0.1644 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1649 - mean_squared_error: 0.1649 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1652 - mean_squared_error: 0.1652 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1648 - mean_squared_error: 0.1648 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1642 - mean_squared_error: 0.1642 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1644 - mean_squared_error: 0.1644 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1652 - mean_squared_error: 0.1652 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1654 - mean_squared_error: 0.1654 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1657 - mean_squared_error: 0.1657 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1642 - mean_squared_error: 0.1642 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1660 - mean_squared_error: 0.1660 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1646 - mean_squared_error: 0.1646 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1651 - mean_squared_error: 0.1651 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1657 - mean_squared_error: 0.1657 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1645 - mean_squared_error: 0.1645 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1643 - mean_squared_error: 0.1643 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1654 - mean_squared_error: 0.1654 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.1642 - mean_squared_error: 0.1642 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1649 - mean_squared_error: 0.1649 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1642 - mean_squared_error: 0.1642 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1651 - mean_squared_error: 0.1651 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1651 - mean_squared_error: 0.1651 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1647 - mean_squared_error: 0.1647 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1642 - mean_squared_error: 0.1642 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1642 - mean_squared_error: 0.1642 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1655 - mean_squared_error: 0.1655 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.1654 - mean_squared_error: 0.1654 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.1641 - mean_squared_error: 0.1641 - val_loss: 0.1600 - val_mean_squared_error: 0.1600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgV7ETw-y1pD"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm0i1SoPrUXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f6cdd94-6c56-4ef1-95f8-567f90899a5a"
      },
      "source": [
        "model.evaluate(test_dataset,steps=500)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 61s 121ms/step - loss: 0.1606 - mean_squared_error: 0.1606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16062970459461212, 0.16062970459461212]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPoRpl8IFNOo",
        "outputId": "39c4b710-b139-40b0-ea09-708b8e773db2"
      },
      "source": [
        "model.save('saved_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7fb8ff2ab110>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x7fb8ff2ab110>, because it is not built.\n",
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_and_return_conditional_losses, residual_block_0_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_2_layer_call_and_return_conditional_losses while saving (showing 5 of 250). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as residual_block_0_layer_call_and_return_conditional_losses, residual_block_0_layer_call_fn, residual_block_1_layer_call_and_return_conditional_losses, residual_block_1_layer_call_fn, residual_block_2_layer_call_and_return_conditional_losses while saving (showing 5 of 250). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDBPD3xYFu_U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNvw1hc1dNX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd2ae1db-0c30-4970-ff8d-4a2995f42094"
      },
      "source": [
        "%load_ext tensorboard\n",
        "!tensorboard --logdir log_dir "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-28 09:08:30.496041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.4.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggZ_G_4Z0Bg0",
        "outputId": "81ac8448-8eb0-4623-90ca-52097fa246d8"
      },
      "source": [
        "!tensorboard dev upload \\\n",
        "  --logdir logs/fit\\\n",
        "  --name \"Mapping network for loudness and F0\" \\\n",
        "  --description \"Mapping of note_number, velocity, instrument_source, qualities, z to f0 scaled, and loudness scaled \" \\\n",
        "  --one_shot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-28 09:29:35.802090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "***** TensorBoard Uploader *****\n",
            "\n",
            "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
            "the following directory:\n",
            "\n",
            "logs/fit\n",
            "\n",
            "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
            "data.\n",
            "\n",
            "Your use of this service is subject to Google's Terms of Service\n",
            "<https://policies.google.com/terms> and Privacy Policy\n",
            "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
            "<https://tensorboard.dev/policy/terms/>.\n",
            "\n",
            "This notice will not be shown again while you are logged into the uploader.\n",
            "To log out, run `tensorboard dev auth revoke`.\n",
            "\n",
            "Continue? (yes/NO) yes\n",
            "\n",
            "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=373649185512-8v619h5kft38l4456nm2dj4ubeqsrvh6.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email&state=RoKQrfTrmk1k3W3xgSd1LXIOAVnR97&prompt=consent&access_type=offline\n",
            "Enter the authorization code: 4/1AY0e-g4wLDVUJXcAJJIdrWoRyB_FHYIxdIgqpILntWkDI6A3gVDep3BM3WI\n",
            "\n",
            "Data for the \"text\" plugin is now uploaded to TensorBoard.dev! Note that uploaded data is public. If you do not want to upload data for this plugin, use the \"--plugins\" command line argument.\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/N7lWbOeGSW6QF6jQIzdXwg/\n",
            "\n",
            "\u001b[1m[2021-03-28T09:29:53]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2021-03-28T09:30:02]\u001b[0m Total uploaded: 400 scalars, 3408 tensors (4.1 MB), 1 binary objects (526.3 kB)\n",
            "\u001b[1m[2021-03-28T09:30:02]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/N7lWbOeGSW6QF6jQIzdXwg/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzKFkTnQG7aZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56cf719b-79f7-4ee7-f34e-72d7943461fa"
      },
      "source": [
        "!cp -r saved_model "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "complete  drive  logs  sample_data  saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3S1x5axG8Ej"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}