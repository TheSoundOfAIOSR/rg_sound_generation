{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mapping Network.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEO2FZbVMl4O"
      },
      "source": [
        "# Purpose\n",
        "This notebook is used to map note_number, velocity, instrument_source, qualities, z to f0_scaled and ld_scaled. It is composed of a LSTM layer, GRU layer and  a dense layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byQTezEBbNRA"
      },
      "source": [
        "# Setup google drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seiaz41x00S_",
        "outputId": "82fc8e9f-706c-488e-cb33-761af44854f6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ3HJu7_5cMK",
        "outputId": "4cb21b1d-b06c-424b-a584-d7c355a569e9"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install -qU ddsp[data_preparation]==1.0.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 174kB 6.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 8.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6MB 9.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 9.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.0MB 44.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 378kB 45.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6MB 22.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.2MB 17.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 17.7MB 257kB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 43.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 40.3MB/s \n",
            "\u001b[?25h  Building wheel for crepe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cloudml-hypertune (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pynndescent 0.5.2 has requirement numba>=0.51.2, but you'll have numba 0.49.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.28.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.28.0 has requirement dill<0.3.2,>=0.3.1.1, but you'll have dill 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.28.0 has requirement future<1.0.0,>=0.18.2, but you'll have future 0.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.28.0 has requirement requests<3.0.0,>=2.24.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27LKzcK5d4ft"
      },
      "source": [
        "# Make directories to save model and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OspCTcni6bYE",
        "outputId": "8b6a1241-f711-4042-c7af-213fb0cdafe0"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "drive_dir = '/content/drive/My Drive/Sound_generation'\n",
        "checkpoint_dir = os.path.join(drive_dir, 'mapping/checkpoint')\n",
        "\n",
        "assert os.path.exists(drive_dir)\n",
        "print('Drive Directory Exists:', drive_dir)\n",
        "\n",
        "!mkdir -p \"$checkpoint_dir\"\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive Directory Exists: /content/drive/My Drive/Sound_generation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a6bDgqpbct_"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlucbB8Hd27v"
      },
      "source": [
        "# Download Complete NSynth Guitar Subse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW2CmoR77k0t",
        "outputId": "832e9c18-ad80-49e5-e55a-f80e74ae15ef"
      },
      "source": [
        "dataset_dir = '/content/complete'\n",
        "train_dataset_dir = os.path.join(dataset_dir, 'train')\n",
        "valid_dataset_dir = os.path.join(dataset_dir, 'valid')\n",
        "test_dataset_dir = os.path.join(dataset_dir, 'test')\n",
        "\n",
        "train_tfrecord_file = os.path.join(train_dataset_dir, 'complete.tfrecord')\n",
        "valid_tfrecord_file = os.path.join(valid_dataset_dir, 'complete.tfrecord')\n",
        "test_tfrecord_file = os.path.join(test_dataset_dir, 'complete.tfrecord')\n",
        "\n",
        "if not os.path.exists(dataset_dir):\n",
        "  train = 'https://osr-tsoai.s3.amazonaws.com/complete/train/complete.tfrecord'\n",
        "  valid = 'https://osr-tsoai.s3.amazonaws.com/complete/valid/complete.tfrecord'\n",
        "  test = 'https://osr-tsoai.s3.amazonaws.com/complete/test/complete.tfrecord'\n",
        "\n",
        "  print(\"Downloading train dataset to {}\\n\".format(train_dataset_dir))\n",
        "  !mkdir -p \"$train_dataset_dir\"\n",
        "  !curl $train --output $train_tfrecord_file\n",
        "\n",
        "  print(\"\\nDownloading valid dataset to {}\\n\".format(valid_dataset_dir))\n",
        "  !mkdir -p \"$valid_dataset_dir\"\n",
        "  !curl $valid --output $valid_tfrecord_file\n",
        "\n",
        "  print(\"\\nDownloading test dataset to {}\\n\".format(test_dataset_dir))\n",
        "  !mkdir -p \"$test_dataset_dir\"\n",
        "  !curl $test --output $test_tfrecord_file"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train dataset to /content/complete/train\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 10.3G  100 10.3G    0     0  63.9M      0  0:02:45  0:02:45 --:--:-- 53.9M\n",
            "\n",
            "Downloading valid dataset to /content/complete/valid\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  675M  100  675M    0     0  67.2M      0  0:00:10  0:00:10 --:--:-- 59.0M\n",
            "\n",
            "Downloading test dataset to /content/complete/test\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  211M  100  211M    0     0  61.2M      0  0:00:03  0:00:03 --:--:-- 61.2M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGVn7_Y7e7_O"
      },
      "source": [
        "# Copying data to drive or from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuYlkUcDdyAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9478e89-836d-4a9b-ad9e-9b261b60ac7f"
      },
      "source": [
        "# !cp -r  /content/drive/MyDrive/Sound_generation/mapping/complete  ./"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFaepHvehLXC"
      },
      "source": [
        "# Defining Data class provider\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVqYQLJNgCdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4fa007-d3b3-4e8d-f34e-6b068484faf1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import ddsp.training.data as data\n",
        "\n",
        "class CompleteTFRecordProvider(data.RecordProvider):\n",
        "  def __init__(self,\n",
        "               file_pattern=None,\n",
        "               example_secs=4,\n",
        "               sample_rate=16000,\n",
        "               frame_rate=250,\n",
        "               map_func=None):\n",
        "    super().__init__(file_pattern, example_secs, sample_rate,\n",
        "                      frame_rate, tf.data.TFRecordDataset)\n",
        "    self._map_func = map_func\n",
        "\n",
        "  def get_dataset(self, shuffle=True):\n",
        "    def parse_tfexample(record):\n",
        "      features = tf.io.parse_single_example(record, self.features_dict)\n",
        "      if self._map_func is not None:\n",
        "        return self._map_func(features)\n",
        "      else:\n",
        "        return features\n",
        "\n",
        "    filenames = tf.data.Dataset.list_files(self._file_pattern, shuffle=shuffle)\n",
        "    dataset = filenames.interleave(\n",
        "        map_func=self._data_format_map_fn,\n",
        "        cycle_length=40,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.map(parse_tfexample,\n",
        "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "  @property\n",
        "  def features_dict(self):\n",
        "    return {\n",
        "      'sample_name':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.string),\n",
        "      'note_number':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'velocity':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'instrument_source':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'qualities':\n",
        "        tf.io.FixedLenFeature([10], dtype=tf.int64),\n",
        "      'audio':\n",
        "        tf.io.FixedLenFeature([self._audio_length], dtype=tf.float32),\n",
        "      'f0_hz':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'f0_confidence':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'loudness_db':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'f0_scaled':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'ld_scaled':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'z':\n",
        "        tf.io.FixedLenFeature([self._feature_length * 16], dtype=tf.float32),\n",
        "    }"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Argument whitelist is deprecated. Please use allowlist.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyLOqJNBhwa-"
      },
      "source": [
        "# Defining feature mapping function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJlzNevzhyul"
      },
      "source": [
        "def features_map(features):\n",
        "  note_number = features['note_number']\n",
        "  velocity = features['velocity']\n",
        "  instrument_source = features['instrument_source']\n",
        "  qualities = features['qualities']\n",
        "  f0_scaled = features['f0_scaled']\n",
        "  ld_scaled = features['ld_scaled']\n",
        "  z = features['z']\n",
        "\n",
        "  sequence_length = f0_scaled.shape[0]\n",
        "\n",
        "  def convert_to_sequence(feature):\n",
        "    channels = feature.shape[0]\n",
        "    feature = tf.expand_dims(feature, axis=0)\n",
        "\n",
        "    feature = tf.broadcast_to(feature, shape=(sequence_length, channels))\n",
        "    feature = tf.cast(feature, dtype=tf.float32)\n",
        "    \n",
        "    return feature\n",
        "\n",
        "  # Normalize data\n",
        "  # 0-127\n",
        "  note_number = note_number / 127\n",
        "  velocity = velocity / 127\n",
        "\n",
        "  # 0-2\n",
        "  # 0\tacoustic, 1\telectronic, 2\tsynthetic\n",
        "  instrument_source = instrument_source / 2\n",
        "\n",
        "  # Prepare dataset for a sequence to sequence mapping\n",
        "  note_number = convert_to_sequence(note_number)\n",
        "  velocity = convert_to_sequence(velocity)\n",
        "  instrument_source = convert_to_sequence(instrument_source)\n",
        "  qualities = convert_to_sequence(qualities)\n",
        "\n",
        "  f0_scaled = tf.expand_dims(f0_scaled, axis=-1)\n",
        "  ld_scaled = tf.expand_dims(ld_scaled, axis=-1)\n",
        "  z = tf.reshape(z, shape=(sequence_length, 16))\n",
        "\n",
        "  input = tf.concat(\n",
        "      [note_number, velocity, instrument_source, qualities, z],\n",
        "      axis=-1)\n",
        "  \n",
        "  output = tf.concat(\n",
        "      [f0_scaled, ld_scaled],\n",
        "      axis=-1)\n",
        "  \n",
        "  return (input, output)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWeUD9z3nLAF"
      },
      "source": [
        "# Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crbnUBoxnMY3"
      },
      "source": [
        "batch_size = 16\n",
        "example_secs = 4\n",
        "sample_rate = 16000\n",
        "frame_rate = 250\n",
        "\n",
        "# Create train dataset\n",
        "train_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=train_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "train_dataset = train_data_provider.get_batch(\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    repeats=-1)\n",
        "\n",
        "# Create valid dataset\n",
        "valid_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=valid_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "valid_dataset = valid_data_provider.get_batch(\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    repeats=-1)\n",
        "\n",
        "# Create test dataset\n",
        "test_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=test_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "test_dataset = test_data_provider.get_batch(\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    repeats=-1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00zdXuekoW0O"
      },
      "source": [
        "# Create and compile mapping model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm3KlXvunN1n"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    tf.keras.layers.GRU(16, return_sequences=True),\n",
        "    tf.keras.layers.Dense(1, activation='tanh')\n",
        "])\n",
        "\n",
        "loss = tf.keras.losses.MeanAbsoluteError()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=loss,\n",
        "    metrics=[tf.keras.losses.MeanSquaredError()])\n",
        "\n",
        "log_dir = \"logs/fit/loudness_f0_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NG0o8Yzpvgf"
      },
      "source": [
        "# Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvuUYIkhprsc",
        "outputId": "6304668e-b4ed-42b1-d31b-4fa1baf637f5"
      },
      "source": [
        "x_train, y_train = next(iter(train_dataset))\n",
        "out = model(x_train)\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (16, 1000, 32)            7936      \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (16, 1000, 16)            2400      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (16, 1000, 1)             17        \n",
            "=================================================================\n",
            "Total params: 10,353\n",
            "Trainable params: 10,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2esZxKsEqU_f"
      },
      "source": [
        "# Load checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KN7G6HFqWuR"
      },
      "source": [
        "checkpoint_file = os.path.join(checkpoint_dir, 'cp.ckpt')\n",
        "\n",
        "if os.path.isdir(checkpoint_dir) and os.listdir(checkpoint_dir):\n",
        "    model.load_weights(checkpoint_file)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_5Ytb13qkdf"
      },
      "source": [
        "# Create training callbacks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-W-3Q5tqXC8"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_file,\n",
        "    save_weights_only=True,\n",
        "    verbose=0,\n",
        "    save_freq='epoch')\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 10:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * 0.9\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhdPr24xquML"
      },
      "source": [
        "# Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFzj98-eqvTB",
        "outputId": "f031edba-07a9-476c-a554-dd1a5d54e076"
      },
      "source": [
        "epochs = 100\n",
        "steps_per_epoch = 100\n",
        "validation_steps = 10\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=epochs,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=valid_dataset,\n",
        "          validation_steps=validation_steps,\n",
        "          callbacks=[checkpoint, lr_scheduler,tensorboard_callback])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 46s 459ms/step - loss: 0.1236 - mean_squared_error: 0.0256 - val_loss: 0.1257 - val_mean_squared_error: 0.0259\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 0.1208 - mean_squared_error: 0.0246 - val_loss: 0.1255 - val_mean_squared_error: 0.0247\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 0.1217 - mean_squared_error: 0.0249 - val_loss: 0.1255 - val_mean_squared_error: 0.0248\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 45s 450ms/step - loss: 0.1197 - mean_squared_error: 0.0245 - val_loss: 0.1250 - val_mean_squared_error: 0.0253\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 45s 450ms/step - loss: 0.1206 - mean_squared_error: 0.0248 - val_loss: 0.1257 - val_mean_squared_error: 0.0240\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 45s 453ms/step - loss: 0.1196 - mean_squared_error: 0.0244 - val_loss: 0.1260 - val_mean_squared_error: 0.0250\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 0.1215 - mean_squared_error: 0.0251 - val_loss: 0.1258 - val_mean_squared_error: 0.0236\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 0.1207 - mean_squared_error: 0.0245 - val_loss: 0.1257 - val_mean_squared_error: 0.0241\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 0.1211 - mean_squared_error: 0.0255 - val_loss: 0.1259 - val_mean_squared_error: 0.0244\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 46s 461ms/step - loss: 0.1208 - mean_squared_error: 0.0246 - val_loss: 0.1255 - val_mean_squared_error: 0.0248\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 46s 459ms/step - loss: 0.1219 - mean_squared_error: 0.0253 - val_loss: 0.1254 - val_mean_squared_error: 0.0247\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 45s 453ms/step - loss: 0.1215 - mean_squared_error: 0.0254 - val_loss: 0.1252 - val_mean_squared_error: 0.0253\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 45s 454ms/step - loss: 0.1202 - mean_squared_error: 0.0251 - val_loss: 0.1251 - val_mean_squared_error: 0.0254\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 46s 456ms/step - loss: 0.1191 - mean_squared_error: 0.0246 - val_loss: 0.1253 - val_mean_squared_error: 0.0257\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 46s 456ms/step - loss: 0.1191 - mean_squared_error: 0.0247 - val_loss: 0.1259 - val_mean_squared_error: 0.0242\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 46s 461ms/step - loss: 0.1223 - mean_squared_error: 0.0255 - val_loss: 0.1262 - val_mean_squared_error: 0.0248\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 47s 474ms/step - loss: 0.1207 - mean_squared_error: 0.0252 - val_loss: 0.1256 - val_mean_squared_error: 0.0251\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 46s 460ms/step - loss: 0.1196 - mean_squared_error: 0.0246 - val_loss: 0.1250 - val_mean_squared_error: 0.0252\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 46s 463ms/step - loss: 0.1156 - mean_squared_error: 0.0239 - val_loss: 0.1252 - val_mean_squared_error: 0.0250\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 47s 475ms/step - loss: 0.1185 - mean_squared_error: 0.0245 - val_loss: 0.1249 - val_mean_squared_error: 0.0255\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 47s 469ms/step - loss: 0.1214 - mean_squared_error: 0.0254 - val_loss: 0.1250 - val_mean_squared_error: 0.0257\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 0.1204 - mean_squared_error: 0.0252 - val_loss: 0.1253 - val_mean_squared_error: 0.0258\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 0.1191 - mean_squared_error: 0.0248 - val_loss: 0.1253 - val_mean_squared_error: 0.0253\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 0.1196 - mean_squared_error: 0.0249 - val_loss: 0.1255 - val_mean_squared_error: 0.0251\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 0.1181 - mean_squared_error: 0.0248 - val_loss: 0.1251 - val_mean_squared_error: 0.0257\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 47s 469ms/step - loss: 0.1175 - mean_squared_error: 0.0243 - val_loss: 0.1252 - val_mean_squared_error: 0.0258\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 0.1195 - mean_squared_error: 0.0253 - val_loss: 0.1253 - val_mean_squared_error: 0.0255\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 0.1194 - mean_squared_error: 0.0251 - val_loss: 0.1252 - val_mean_squared_error: 0.0253\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 46s 456ms/step - loss: 0.1179 - mean_squared_error: 0.0245 - val_loss: 0.1252 - val_mean_squared_error: 0.0250\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 0.1200 - mean_squared_error: 0.0253 - val_loss: 0.1251 - val_mean_squared_error: 0.0256\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 46s 455ms/step - loss: 0.1190 - mean_squared_error: 0.0248 - val_loss: 0.1250 - val_mean_squared_error: 0.0255\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 46s 456ms/step - loss: 0.1218 - mean_squared_error: 0.0257 - val_loss: 0.1251 - val_mean_squared_error: 0.0257\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 0.1202 - mean_squared_error: 0.0255 - val_loss: 0.1249 - val_mean_squared_error: 0.0257\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 46s 461ms/step - loss: 0.1188 - mean_squared_error: 0.0252 - val_loss: 0.1251 - val_mean_squared_error: 0.0255\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 47s 474ms/step - loss: 0.1166 - mean_squared_error: 0.0244 - val_loss: 0.1251 - val_mean_squared_error: 0.0252\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 0.1217 - mean_squared_error: 0.0255 - val_loss: 0.1253 - val_mean_squared_error: 0.0255\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 47s 465ms/step - loss: 0.1196 - mean_squared_error: 0.0250 - val_loss: 0.1250 - val_mean_squared_error: 0.0256\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 46s 460ms/step - loss: 0.1191 - mean_squared_error: 0.0250 - val_loss: 0.1250 - val_mean_squared_error: 0.0255\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 46s 459ms/step - loss: 0.1165 - mean_squared_error: 0.0243 - val_loss: 0.1249 - val_mean_squared_error: 0.0254\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 0.1171 - mean_squared_error: 0.0244 - val_loss: 0.1249 - val_mean_squared_error: 0.0256\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 0.1194 - mean_squared_error: 0.0251 - val_loss: 0.1251 - val_mean_squared_error: 0.0253\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 45s 455ms/step - loss: 0.1206 - mean_squared_error: 0.0253 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 45s 454ms/step - loss: 0.1188 - mean_squared_error: 0.0248 - val_loss: 0.1251 - val_mean_squared_error: 0.0255\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 0.1183 - mean_squared_error: 0.0247 - val_loss: 0.1250 - val_mean_squared_error: 0.0255\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 46s 464ms/step - loss: 0.1192 - mean_squared_error: 0.0250 - val_loss: 0.1250 - val_mean_squared_error: 0.0255\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 47s 469ms/step - loss: 0.1176 - mean_squared_error: 0.0246 - val_loss: 0.1249 - val_mean_squared_error: 0.0255\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 0.1173 - mean_squared_error: 0.0246 - val_loss: 0.1249 - val_mean_squared_error: 0.0255\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 45s 453ms/step - loss: 0.1193 - mean_squared_error: 0.0254 - val_loss: 0.1250 - val_mean_squared_error: 0.0253\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 0.1185 - mean_squared_error: 0.0248 - val_loss: 0.1250 - val_mean_squared_error: 0.0255\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 0.1190 - mean_squared_error: 0.0252 - val_loss: 0.1250 - val_mean_squared_error: 0.0256\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 0.1196 - mean_squared_error: 0.0251 - val_loss: 0.1250 - val_mean_squared_error: 0.0253\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 45s 453ms/step - loss: 0.1211 - mean_squared_error: 0.0255 - val_loss: 0.1250 - val_mean_squared_error: 0.0255\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 45s 447ms/step - loss: 0.1201 - mean_squared_error: 0.0253 - val_loss: 0.1249 - val_mean_squared_error: 0.0254\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 45s 454ms/step - loss: 0.1185 - mean_squared_error: 0.0251 - val_loss: 0.1250 - val_mean_squared_error: 0.0255\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 45s 453ms/step - loss: 0.1177 - mean_squared_error: 0.0247 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 46s 456ms/step - loss: 0.1183 - mean_squared_error: 0.0247 - val_loss: 0.1249 - val_mean_squared_error: 0.0253\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 49s 489ms/step - loss: 0.1205 - mean_squared_error: 0.0251 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 45s 453ms/step - loss: 0.1198 - mean_squared_error: 0.0253 - val_loss: 0.1250 - val_mean_squared_error: 0.0255\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 45s 454ms/step - loss: 0.1188 - mean_squared_error: 0.0248 - val_loss: 0.1250 - val_mean_squared_error: 0.0255\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 45s 454ms/step - loss: 0.1150 - mean_squared_error: 0.0240 - val_loss: 0.1249 - val_mean_squared_error: 0.0254\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 0.1175 - mean_squared_error: 0.0245 - val_loss: 0.1249 - val_mean_squared_error: 0.0255\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 45s 455ms/step - loss: 0.1209 - mean_squared_error: 0.0255 - val_loss: 0.1250 - val_mean_squared_error: 0.0255\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 45s 455ms/step - loss: 0.1196 - mean_squared_error: 0.0251 - val_loss: 0.1249 - val_mean_squared_error: 0.0255\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 0.1179 - mean_squared_error: 0.0247 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 0.1191 - mean_squared_error: 0.0250 - val_loss: 0.1249 - val_mean_squared_error: 0.0254\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 46s 461ms/step - loss: 0.1179 - mean_squared_error: 0.0247 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 46s 463ms/step - loss: 0.1166 - mean_squared_error: 0.0242 - val_loss: 0.1249 - val_mean_squared_error: 0.0255\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.1189 - mean_squared_error: 0.0252 - val_loss: 0.1249 - val_mean_squared_error: 0.0255\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 46s 459ms/step - loss: 0.1202 - mean_squared_error: 0.0255 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 46s 459ms/step - loss: 0.1168 - mean_squared_error: 0.0245 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 0.1209 - mean_squared_error: 0.0255 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 46s 460ms/step - loss: 0.1193 - mean_squared_error: 0.0251 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 0.1216 - mean_squared_error: 0.0258 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 45s 454ms/step - loss: 0.1184 - mean_squared_error: 0.0249 - val_loss: 0.1250 - val_mean_squared_error: 0.0255\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 45s 455ms/step - loss: 0.1191 - mean_squared_error: 0.0251 - val_loss: 0.1249 - val_mean_squared_error: 0.0254\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 45s 453ms/step - loss: 0.1162 - mean_squared_error: 0.0243 - val_loss: 0.1249 - val_mean_squared_error: 0.0254\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 0.1221 - mean_squared_error: 0.0255 - val_loss: 0.1249 - val_mean_squared_error: 0.0254\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 45s 455ms/step - loss: 0.1202 - mean_squared_error: 0.0252 - val_loss: 0.1249 - val_mean_squared_error: 0.0254\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 45s 453ms/step - loss: 0.1177 - mean_squared_error: 0.0247 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 0.1158 - mean_squared_error: 0.0240 - val_loss: 0.1249 - val_mean_squared_error: 0.0254\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 45s 454ms/step - loss: 0.1176 - mean_squared_error: 0.0245 - val_loss: 0.1249 - val_mean_squared_error: 0.0254\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 46s 459ms/step - loss: 0.1195 - mean_squared_error: 0.0251 - val_loss: 0.1249 - val_mean_squared_error: 0.0254\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 0.1206 - mean_squared_error: 0.0253 - val_loss: 0.1249 - val_mean_squared_error: 0.0254\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 0.1191 - mean_squared_error: 0.0250 - val_loss: 0.1249 - val_mean_squared_error: 0.0254\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 46s 460ms/step - loss: 0.1170 - mean_squared_error: 0.0244 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 0.1195 - mean_squared_error: 0.0251 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 46s 456ms/step - loss: 0.1170 - mean_squared_error: 0.0243 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 0.1181 - mean_squared_error: 0.0249 - val_loss: 0.1249 - val_mean_squared_error: 0.0254\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 46s 465ms/step - loss: 0.1190 - mean_squared_error: 0.0252 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 47s 465ms/step - loss: 0.1190 - mean_squared_error: 0.0251 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 0.1190 - mean_squared_error: 0.0250 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 46s 460ms/step - loss: 0.1193 - mean_squared_error: 0.0252 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 46s 456ms/step - loss: 0.1206 - mean_squared_error: 0.0254 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 0.1200 - mean_squared_error: 0.0253 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 47s 468ms/step - loss: 0.1190 - mean_squared_error: 0.0252 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 0.1171 - mean_squared_error: 0.0244 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 0.1190 - mean_squared_error: 0.0249 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 46s 463ms/step - loss: 0.1204 - mean_squared_error: 0.0251 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 0.1198 - mean_squared_error: 0.0252 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 0.1173 - mean_squared_error: 0.0244 - val_loss: 0.1250 - val_mean_squared_error: 0.0254\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f16762abc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgV7ETw-y1pD"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm0i1SoPrUXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c3c49d-ca02-44d1-afe5-6aae9c61919c"
      },
      "source": [
        "model.evaluate(test_dataset,steps=500)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 59s 117ms/step - loss: 0.1282 - mean_squared_error: 0.0269\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12817637622356415, 0.026893505826592445]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNvw1hc1dNX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5170f5a4-b9d5-4891-c148-385249b91b76"
      },
      "source": [
        "%load_ext tensorboard\n",
        "!tensorboard --logdir log_dir "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-20 13:25:54.314900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.4.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
            "Error in atexit._run_exitfuncs:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 320, in _exit_function\n",
            "    def _exit_function(info=info, debug=debug, _run_finalizers=_run_finalizers,\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggZ_G_4Z0Bg0",
        "outputId": "76941311-3b84-41f0-96ed-075fb3151341"
      },
      "source": [
        "!tensorboard dev upload \\\n",
        "  --logdir logs/fit\\\n",
        "  --name \"Mapping network for loudness and F0\" \\\n",
        "  --description \"Mapping of note_number, velocity, instrument_source, qualities, z to f0 scaled, and loudness scaled \" \\\n",
        "  --one_shot"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-20 13:28:32.139712: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Data for the \"text\" plugin is now uploaded to TensorBoard.dev! Note that uploaded data is public. If you do not want to upload data for this plugin, use the \"--plugins\" command line argument.\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/BA5eBbr1RCGqcgpjtqd0jg/\n",
            "\n",
            "\u001b[1m[2021-03-20T13:28:34]\u001b[0m Started scanning logdir.\n",
            "E0320 13:28:35.580111 140047838578560 uploader.py:1114] Attempted to re-upload existing blob.  Skipping.\n",
            "\u001b[1m[2021-03-20T13:28:37]\u001b[0m Total uploaded: 460 scalars, 922 tensors (1.1 MB), 1 binary objects (300.0 kB)\n",
            "\u001b[90mTotal skipped: 1 binary objects (300.0 kB)\n",
            "\u001b[0m\u001b[1m[2021-03-20T13:28:37]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/BA5eBbr1RCGqcgpjtqd0jg/\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}