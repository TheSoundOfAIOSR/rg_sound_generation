{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "harmonic_dataset_demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0fVn8yUJl_v"
      },
      "source": [
        "## Setup Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTjJuD9AmeYy"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxRUhnmKsUj9"
      },
      "source": [
        "### Download Harmonic NSynth Guitar Subset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTVOibF9sb3y"
      },
      "source": [
        "# '''This one download the folder recursively'''\n",
        "# def folder_download(folder_id):\n",
        "#   # authenticate\n",
        "#   from google.colab import auth\n",
        "#   auth.authenticate_user()\n",
        "#   # get folder_name\n",
        "#   from googleapiclient.discovery import build\n",
        "#   service = build('drive', 'v3')\n",
        "#   folder_name = service.files().get(fileId=folder_id).execute()['name']\n",
        "#   # import library and download\n",
        "#   !wget -qnc https://github.com/segnolin/google-drive-folder-downloader/raw/master/download.py\n",
        "#   from download import download_folder\n",
        "#   download_folder(service, folder_id, './', folder_name)\n",
        "#   return folder_name\n",
        "\n",
        "# dataset_dir = '/content/harmonic_dataset'\n",
        "# if not os.path.exists(dataset_dir):\n",
        "#   folder_name = folder_download('19gLqATp6-fLTOIE1z4pGmey0BvVJBjqG')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dDJO8aq7PG3"
      },
      "source": [
        "### Access Harmonic NSynth Guitar Subset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NIEyEX3YXvH"
      },
      "source": [
        "dataset_dir = '/content/drive/My Drive/nsynth_guitar/dataset/harmonic'"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn7CQ4GQizHy"
      },
      "source": [
        "## Install Dependencies\n",
        "\n",
        "First we install the required dependencies with `pip`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjhdKFJbvRVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af4e3a13-0ae9-4afc-ec73-40e82a202482"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install -qU ddsp[data_preparation]==1.0.1"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.9MB 3.0MB/s \n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9AWf8NpBiB4"
      },
      "source": [
        "## Define DataProvider class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB0sWNuRoW4I"
      },
      "source": [
        "import tensorflow as tf\n",
        "import ddsp.training.data as data\n",
        "\n",
        "\n",
        "class HarmonicTFRecordProvider(data.RecordProvider):\n",
        "  def __init__(self,\n",
        "               file_pattern=None,\n",
        "               example_secs=4,\n",
        "               sample_rate=16000,\n",
        "               frame_rate=250,\n",
        "               map_func=None):\n",
        "    super().__init__(file_pattern, example_secs, sample_rate,\n",
        "                      frame_rate, tf.data.TFRecordDataset)\n",
        "    self._map_func = map_func\n",
        "\n",
        "  def get_dataset(self, shuffle=True):\n",
        "    def parse_tfexample(record):\n",
        "      features = tf.io.parse_single_example(record, self.features_dict)\n",
        "      if self._map_func is not None:\n",
        "        return self._map_func(features)\n",
        "      else:\n",
        "        return features\n",
        "\n",
        "    filenames = tf.data.Dataset.list_files(self._file_pattern, shuffle=shuffle)\n",
        "    dataset = filenames.interleave(\n",
        "        map_func=self._data_format_map_fn,\n",
        "        cycle_length=40,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.map(parse_tfexample,\n",
        "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "  @property\n",
        "  def features_dict(self):\n",
        "    return {\n",
        "      'sample_name':\n",
        "        tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "      'note_number':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'velocity':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'instrument_source':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'qualities':\n",
        "        tf.io.FixedLenFeature([10], dtype=tf.int64),\n",
        "      'audio':\n",
        "        tf.io.FixedLenFeature([self._audio_length], dtype=tf.float32),\n",
        "      'f0_hz':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'f0_confidence':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'loudness_db':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'f0_estimate':\n",
        "        tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "      'h_freq':\n",
        "        tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "      'h_mag':\n",
        "        tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "      'h_phase':\n",
        "        tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "    }"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbUpwtyRB8wV"
      },
      "source": [
        "## Define features map function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbXhqrZaB5rw"
      },
      "source": [
        "def features_map(features):\n",
        "    sample_name = features['sample_name']\n",
        "    note_number = features['note_number']\n",
        "    velocity = features['velocity']\n",
        "    instrument_source = features['instrument_source']\n",
        "    qualities = features['qualities']\n",
        "    audio = features['audio']\n",
        "    f0_hz = features['f0_hz']\n",
        "    f0_confidence = features['f0_confidence']\n",
        "    loudness_db = features['loudness_db']\n",
        "    f0_estimate = features['f0_estimate']\n",
        "    h_freq = features['h_freq']\n",
        "    h_mag = features['h_mag']\n",
        "    h_phase = features['h_phase']\n",
        "\n",
        "    f0_estimate = tf.io.parse_tensor(f0_estimate, out_type=tf.float32)\n",
        "    h_freq = tf.io.parse_tensor(h_freq, out_type=tf.float32)\n",
        "    h_mag = tf.io.parse_tensor(h_mag, out_type=tf.float32)\n",
        "    h_phase = tf.io.parse_tensor(h_phase, out_type=tf.float32)\n",
        "\n",
        "    element_dict = {\n",
        "        'sample_name': sample_name,\n",
        "        'note_number': note_number,\n",
        "        'velocity': velocity,\n",
        "        'instrument_source': instrument_source,\n",
        "        'qualities': qualities,\n",
        "        'audio': audio,\n",
        "        'f0_hz': f0_hz,\n",
        "        'f0_confidence': f0_confidence,\n",
        "        'loudness_db': loudness_db,\n",
        "        'f0_estimate': f0_estimate,\n",
        "        'h_freq': h_freq,\n",
        "        'h_mag': h_mag,\n",
        "        'h_phase': h_phase,\n",
        "    }\n",
        "\n",
        "    return element_dict"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7dYOU811Ni4"
      },
      "source": [
        "## Create datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBa055Xy1MIL"
      },
      "source": [
        "train_dataset_dir = os.path.join(dataset_dir, 'train')\n",
        "valid_dataset_dir = os.path.join(dataset_dir, 'valid')\n",
        "test_dataset_dir = os.path.join(dataset_dir, 'test')\n",
        "\n",
        "train_tfrecord_file = os.path.join(train_dataset_dir, 'harmonic.tfrecord')\n",
        "valid_tfrecord_file = os.path.join(valid_dataset_dir, 'harmonic.tfrecord')\n",
        "test_tfrecord_file = os.path.join(test_dataset_dir, 'harmonic.tfrecord')\n",
        "\n",
        "example_secs = 4\n",
        "sample_rate = 16000\n",
        "frame_rate = 250\n",
        "\n",
        "# Create train dataset\n",
        "train_data_provider = HarmonicTFRecordProvider(\n",
        "    file_pattern=train_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "train_dataset = train_data_provider.get_batch(1, shuffle=False, repeats=1)\n",
        "\n",
        "# Create valid dataset\n",
        "valid_data_provider = HarmonicTFRecordProvider(\n",
        "    file_pattern=valid_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "valid_dataset = valid_data_provider.get_batch(1, shuffle=False, repeats=1)\n",
        "\n",
        "# Create test dataset\n",
        "test_data_provider = HarmonicTFRecordProvider(\n",
        "    file_pattern=test_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "test_dataset = test_data_provider.get_batch(1, shuffle=False, repeats=1)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zaV0jB_Gh-2"
      },
      "source": [
        "## Harmonic Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxWIVnorGdzY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def mod_cumsum(x, mod):\n",
        "    size = x.shape[1]\n",
        "    y = tf.TensorArray(tf.float32, size=size, dynamic_size=False)\n",
        "\n",
        "    x = x % mod\n",
        "    s = tf.gather(x, 0, axis=1) * 0.0\n",
        "    for i in tf.range(size):\n",
        "        v = tf.gather(x, i, axis=1)\n",
        "        s = (s + v) % mod\n",
        "        y = y.write(i, s)\n",
        "\n",
        "    y = y.stack()\n",
        "    y = tf.transpose(y, perm=(1, 0, 2))\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "def generate_phase(h_freq, sample_rate, frame_step, initial_h_phase=None):\n",
        "    if initial_h_phase is None:\n",
        "        initial_h_phase = tf.zeros((h_freq.shape[0], 1, h_freq.shape[2]))\n",
        "\n",
        "    frame_rate = sample_rate / frame_step\n",
        "    norm_omega = 0.5 * (h_freq[:, :-1, :] + h_freq[:, 1:, :]) / frame_rate\n",
        "    h_phase = mod_cumsum(norm_omega, 1.0)\n",
        "    h_phase = tf.pad(h_phase, ((0, 0), (1, 0), (0, 0))) + initial_h_phase\n",
        "    h_phase = h_phase % 1.0\n",
        "    h_phase = h_phase * (2.0 * np.pi)\n",
        "\n",
        "    return h_phase\n",
        "\n",
        "\n",
        "def harmonic_synthesis(h_freq, h_mag, h_phase, sample_rate, frame_step):\n",
        "    # remove components above nyquist frequency\n",
        "    h_mag = tf.where(\n",
        "        tf.greater_equal(h_freq, sample_rate / 2.0),\n",
        "        tf.zeros_like(h_mag), h_mag)\n",
        "\n",
        "    h_freq = tf.expand_dims(h_freq, axis=-1)\n",
        "    h_phase = tf.expand_dims(h_phase, axis=-1)\n",
        "    h_mag = tf.expand_dims(h_mag, axis=-1)\n",
        "\n",
        "    # triangular window\n",
        "    window = tf.range(0, frame_step + 1, dtype=tf.float32) / frame_step\n",
        "    window = tf.concat([window[:-1], window[::-1]], axis=0)\n",
        "    window = window[tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "    # time axis\n",
        "    t = tf.range(-frame_step, frame_step + 1, dtype=tf.float32) / sample_rate\n",
        "    t = t[tf.newaxis, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "    phases = 2.0 * np.pi * h_freq * t + h_phase\n",
        "    wavs = tf.cos(phases)\n",
        "    wavs = h_mag * wavs\n",
        "    wavs = tf.reduce_sum(wavs, axis=-2)\n",
        "    wavs = window * wavs\n",
        "    audio = tf.signal.overlap_and_add(wavs, frame_step)\n",
        "    audio = audio[:, frame_step:-(frame_step + 1)]\n",
        "\n",
        "    return audio\n",
        "\n",
        "\n",
        "class HarmonicModel(tf.keras.Model):\n",
        "    def __init__(self, sample_rate, frame_step, batches, frames, harmonics,\n",
        "                 h_freq=None, h_mag=None, h_phase=None, generate_phase=False):\n",
        "        super(HarmonicModel, self).__init__()\n",
        "        self.sample_rate = sample_rate\n",
        "        self.frame_step = frame_step\n",
        "        self.batches = batches\n",
        "        self.frames = frames\n",
        "        self.harmonics = harmonics\n",
        "\n",
        "        if h_freq is None:\n",
        "            h_freq = tf.zeros(shape=(1, 1, 1))\n",
        "        if h_mag is None:\n",
        "            h_mag = tf.zeros(shape=(1, 1, 1))\n",
        "        if h_phase is None:\n",
        "            h_phase = tf.zeros(shape=(1, 1, 1))\n",
        "\n",
        "        self._h_freq = h_freq\n",
        "        self._h_mag = h_mag\n",
        "        self._h_phase = h_phase\n",
        "        self.generate_phase = generate_phase\n",
        "\n",
        "        self._shifts = self.add_weight(\n",
        "            name='shifts',\n",
        "            shape=(self.batches, self.frames, self.harmonics, 3),\n",
        "            dtype=tf.float32,\n",
        "            initializer=tf.keras.initializers.Zeros(),\n",
        "            trainable=True)\n",
        "\n",
        "    @property\n",
        "    def h_freq_shift(self):\n",
        "        return self._shifts[:, :, :, 0]\n",
        "\n",
        "    @property\n",
        "    def h_mag_shift(self):\n",
        "        return self._shifts[:, :, :, 1]\n",
        "\n",
        "    @property\n",
        "    def h_phase_shift(self):\n",
        "        return self._shifts[:, :, :, 2]\n",
        "\n",
        "    @property\n",
        "    def h_freq(self):\n",
        "        frame_rate = self.sample_rate / self.frame_step\n",
        "        return self._h_freq + frame_rate * self.h_freq_shift\n",
        "    \n",
        "    @h_freq.setter\n",
        "    def h_freq(self, value):\n",
        "        frame_rate = self.sample_rate / self.frame_step\n",
        "        self._h_freq = value - frame_rate * self.h_freq_shift\n",
        "\n",
        "    @property\n",
        "    def h_mag(self):\n",
        "        return self._h_mag + self.h_mag_shift\n",
        "\n",
        "    @h_mag.setter\n",
        "    def h_mag(self, value):\n",
        "        self._h_mag = value - self.h_mag_shift\n",
        "\n",
        "    @property\n",
        "    def h_phase(self):\n",
        "        return self._h_phase + 2.0 * np.pi * self.h_phase_shift\n",
        "\n",
        "    @h_phase.setter\n",
        "    def h_phase(self, value):\n",
        "        self._h_phase = value - 2.0 * np.pi * self.h_phase_shift\n",
        "\n",
        "    def call(self, inputs=None, training=None, mask=None):\n",
        "        sample_rate = self.sample_rate\n",
        "        frame_step = self.frame_step\n",
        "\n",
        "        h_freq = self.h_freq\n",
        "        h_phase = self.h_phase\n",
        "        h_mag = self.h_mag\n",
        "\n",
        "        if self.generate_phase:\n",
        "            h_phase = generate_phase(h_freq, sample_rate, frame_step,\n",
        "                                     initial_h_phase=None)\n",
        "\n",
        "        audio = harmonic_synthesis(\n",
        "            h_freq, h_mag, h_phase, sample_rate, frame_step)\n",
        "\n",
        "        return audio\n",
        "\n",
        "    def get_config(self):\n",
        "        pass"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWGs0WJXzYDT"
      },
      "source": [
        "## Display harmonic decomposition results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mgP0TO8JH1e"
      },
      "source": [
        "iterator = iter(train_dataset)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zasYW880HL5g"
      },
      "source": [
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
        "\n",
        "e = next(iterator)\n",
        "\n",
        "sample_name = e['sample_name'][0].numpy().decode('UTF-8')\n",
        "note_number = e['note_number']\n",
        "velocity = e['velocity']\n",
        "instrument_source = e['instrument_source']\n",
        "qualities = e['qualities']\n",
        "audio = e['audio']\n",
        "f0_hz = e['f0_hz']\n",
        "f0_confidence = e['f0_confidence']\n",
        "loudness_db = e['loudness_db']\n",
        "\n",
        "f0_estimate = e['f0_estimate']\n",
        "h_freq = e['h_freq']\n",
        "h_mag = e['h_mag']\n",
        "h_phase = e['h_phase']\n",
        "\n",
        "print(f'sample_name: {sample_name}')\n",
        "print(f'note_number: {int(note_number[0][0])}')\n",
        "print(f'velocity: {int(velocity[0][0])}')\n",
        "\n",
        "audio = tf.cast(audio, dtype=tf.float32)\n",
        "audio = tf.reshape(audio, shape=(1, -1))\n",
        "\n",
        "frame_step = 64\n",
        "\n",
        "# f0_estimate = tf.reshape(e['f0_hz'][0], shape=(1, -1, 1))\n",
        "# f0_estimate = tf.pad(f0_estimate, ((0, 0), (0, 1), (0, 0)))\n",
        "# f0_mean = non_zero_mean(f0_estimate, axis=1)\n",
        "# f0_estimate = tf.where(f0_estimate > 0.0, f0_estimate, f0_mean)\n",
        "\n",
        "harmonic_model = HarmonicModel(\n",
        "    sample_rate=sample_rate,\n",
        "    frame_step=frame_step,\n",
        "    batches=h_freq.shape[0],\n",
        "    frames=h_freq.shape[1],\n",
        "    harmonics=h_freq.shape[2],\n",
        "    h_freq=h_freq, h_mag=h_mag, h_phase=h_phase,\n",
        "    generate_phase=False)\n",
        "\n",
        "harmonic = harmonic_model([])\n",
        "residual = audio - harmonic\n",
        "\n",
        "harmonic_model.generate_phase = True\n",
        "no_phase = harmonic_model([])\n",
        "\n",
        "original = np.squeeze(audio.numpy())\n",
        "harmonic = np.squeeze(harmonic.numpy())\n",
        "residual = np.squeeze(residual.numpy())\n",
        "no_phase = np.squeeze(no_phase.numpy())\n",
        "\n",
        "sf.write('original.wav', 0.5 * original, sample_rate)\n",
        "sf.write('harmonic.wav', 0.5 * harmonic, sample_rate)\n",
        "sf.write('residual.wav', 0.5 * residual, sample_rate)\n",
        "sf.write('no_phase.wav', 0.5 * no_phase, sample_rate)\n",
        "\n",
        "print('\\nOriginal\\n')\n",
        "IPython.display.display(IPython.display.Audio('original.wav'))\n",
        "print('\\nHarmonic\\n')\n",
        "IPython.display.display(IPython.display.Audio('harmonic.wav'))\n",
        "print('\\nResidual\\n')\n",
        "IPython.display.display(IPython.display.Audio('residual.wav'))\n",
        "print('\\nNo Phase\\n')\n",
        "IPython.display.display(IPython.display.Audio('no_phase.wav'))\n",
        "\n",
        "def specgrams(x):\n",
        "    plt.figure()\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.specgram(x, NFFT=256, Fs=sample_rate, window=None,\n",
        "                  noverlap=256 - frame_step, mode='psd', vmin=-180)\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.specgram(x, NFFT=1024, Fs=sample_rate, window=None,\n",
        "                  noverlap=1024 - frame_step, mode='psd', vmin=-180)\n",
        "    plt.show()\n",
        "\n",
        "print('\\nWaveforms\\n')\n",
        "plt.figure()\n",
        "plt.plot(original, label='original')\n",
        "plt.plot(harmonic, label='harmonic')\n",
        "plt.plot(no_phase, label='no_phase')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print('\\nF0 estimate\\n')\n",
        "plt.figure()\n",
        "plt.plot(np.squeeze(f0_estimate.numpy()))\n",
        "plt.show()\n",
        "\n",
        "print('\\nFrequency tracks\\n')\n",
        "plt.figure()\n",
        "h_freq = harmonic_model.h_freq\n",
        "h_freq = tf.where(h_freq == 0.0, np.inf, h_freq)\n",
        "plt.plot(np.squeeze(h_freq.numpy()))\n",
        "plt.show()\n",
        "\n",
        "print('\\nOriginal spectorgram\\n')\n",
        "specgrams(original)\n",
        "print('\\nHarmonic spectorgram\\n')\n",
        "specgrams(harmonic)\n",
        "print('\\nResidual spectorgram\\n')\n",
        "specgrams(residual)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}