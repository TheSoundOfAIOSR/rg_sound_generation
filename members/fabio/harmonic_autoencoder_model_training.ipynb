{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "harmonic_autoencoder_model_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcAvS4amzDrZ"
      },
      "source": [
        "# Mapping model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0fVn8yUJl_v"
      },
      "source": [
        "## Setup Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m33xuTjEKazJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40af6b87-16f7-468f-e86d-e5e89a921a48"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LVV4Dc61HHY"
      },
      "source": [
        "## Make directories to save model and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XJcymGj1IwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65089c4a-ac52-45f8-ee63-71ebe8609b0b"
      },
      "source": [
        "import os\n",
        "\n",
        "drive_dir = '/content/drive/My Drive/nsynth_guitar'\n",
        "checkpoint_dir = os.path.join(drive_dir, 'harmonic_autoencoder/checkpoint')\n",
        "\n",
        "assert os.path.exists(drive_dir)\n",
        "print('Drive Directory Exists:', drive_dir)\n",
        "\n",
        "!mkdir -p \"$checkpoint_dir\""
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive Directory Exists: /content/drive/My Drive/nsynth_guitar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fgGZzyMGyA4"
      },
      "source": [
        "## Clear existing checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYaZoeNeGrvo"
      },
      "source": [
        "import shutil\n",
        "\n",
        "try:\n",
        "    shutil.rmtree(checkpoint_dir)\n",
        "except OSError as e:\n",
        "    print(\"Error: %s : %s\" % (checkpoint_dir, e.strerror))"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn7CQ4GQizHy"
      },
      "source": [
        "## Install Dependencies\n",
        "\n",
        "First we install the required dependencies with `pip`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjhdKFJbvRVU"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install git+https://github.com/fabiodimarco/tf-spectral-modeling-synthesis\n",
        "!pip install -q ddsp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9AWf8NpBiB4"
      },
      "source": [
        "## Define DataProvider class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6180WP6AkkJ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import ddsp.training.data as data\n",
        "\n",
        "\n",
        "class CompleteTFRecordProvider(data.RecordProvider):\n",
        "    def __init__(self,\n",
        "                 file_pattern=None,\n",
        "                 example_secs=4,\n",
        "                 sample_rate=16000,\n",
        "                 frame_rate=250,\n",
        "                 map_func=None):\n",
        "        super().__init__(file_pattern, example_secs, sample_rate,\n",
        "                         frame_rate, tf.data.TFRecordDataset)\n",
        "        self._map_func = map_func\n",
        "\n",
        "    def get_dataset(self, shuffle=True):\n",
        "        def parse_tfexample(record):\n",
        "            features = tf.io.parse_single_example(record, self.features_dict)\n",
        "            if self._map_func is not None:\n",
        "                return self._map_func(features)\n",
        "            else:\n",
        "                return features\n",
        "\n",
        "        filenames = tf.data.Dataset.list_files(\n",
        "            self._file_pattern, shuffle=shuffle)\n",
        "        dataset = filenames.interleave(\n",
        "            map_func=self._data_format_map_fn,\n",
        "            cycle_length=40,\n",
        "            num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
        "            deterministic=True)\n",
        "        dataset = dataset.map(\n",
        "            parse_tfexample,\n",
        "            num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
        "            deterministic=True)\n",
        "        return dataset\n",
        "\n",
        "    @property\n",
        "    def features_dict(self):\n",
        "        return {\n",
        "            'sample_name': tf.io.FixedLenFeature([1], dtype=tf.string),\n",
        "            'instrument_id': tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "            'note_number': tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "            'velocity': tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "            'instrument_source': tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "            'qualities': tf.io.FixedLenFeature([10], dtype=tf.int64),\n",
        "            'audio': tf.io.FixedLenFeature([self._audio_length], dtype=tf.float32),\n",
        "            'f0_hz': tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "            'f0_confidence': tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "            'loudness_db': tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "            'f0_scaled': tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "            'ld_scaled': tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "            'z': tf.io.FixedLenFeature([self._feature_length * 16], dtype=tf.float32),\n",
        "            'f0_estimate': tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "            'h_freq': tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "            'h_mag': tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "            'h_phase': tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "        }"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbUpwtyRB8wV"
      },
      "source": [
        "## Define features map function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbXhqrZaB5rw"
      },
      "source": [
        "import tsms\n",
        "\n",
        "\n",
        "min_note_number = 40\n",
        "max_note_number = 88\n",
        "max_harmonics = 98\n",
        "sample_rate = 16000\n",
        "frame_step = 64\n",
        "frame_rate = sample_rate // frame_step\n",
        "example_secs = 4\n",
        "\n",
        "\n",
        "def normalize_h_freq(h_freq, h_mag, note_number):\n",
        "    f0 = tsms.core.harmonic_analysis_to_f0(h_freq, h_mag)\n",
        "    f0_mean = tf.math.reduce_mean(f0, axis=1)\n",
        "    note_number = tf.cast(note_number, dtype=tf.float32)\n",
        "    f0_note = tsms.core.midi_to_hz(note_number)\n",
        "\n",
        "    harmonics = tf.shape(h_freq)[-1]\n",
        "    harmonic_indices = tf.range(1, harmonics + 1, dtype=tf.float32)\n",
        "    harmonic_indices = harmonic_indices[tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "    st_var = (2.0 ** (1.0 / 12.0) - 1.0)\n",
        "\n",
        "    h_freq_mean = f0_mean * harmonic_indices\n",
        "    h_freq_note = f0_note * harmonic_indices\n",
        "\n",
        "    h_freq_norm = (h_freq - h_freq_mean) / (h_freq_note * st_var)\n",
        "\n",
        "    return h_freq_norm\n",
        "\n",
        "\n",
        "def denormalize_h_freq(h_freq_norm, note_number):\n",
        "    note_number = tf.cast(note_number, dtype=tf.float32)\n",
        "    f0_note = tsms.core.midi_to_hz(note_number)\n",
        "\n",
        "    harmonics = tf.shape(h_freq_norm)[-1]\n",
        "    harmonic_indices = tf.range(1, harmonics + 1, dtype=tf.float32)\n",
        "    harmonic_indices = harmonic_indices[tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "    st_var = (2.0 ** (1.0 / 12.0) - 1.0)\n",
        "\n",
        "    h_freq_note = f0_note * harmonic_indices\n",
        "\n",
        "    h_freq = h_freq_note * (h_freq_norm * st_var + 1.0)\n",
        "\n",
        "    return h_freq\n",
        "\n",
        "\n",
        "def normalize_h_mag(h_mag, db_limit=-120.0):\n",
        "    h_mag = tsms.core.lin_to_db(h_mag)\n",
        "    h_mag = h_mag - tf.math.reduce_max(h_mag)\n",
        "    h_mag_norm = (tf.maximum(h_mag, db_limit) - db_limit) / (-db_limit)\n",
        "\n",
        "    return h_mag_norm\n",
        "\n",
        "\n",
        "def denormalize_h_mag(h_mag_norm, db_limit=-120.0):\n",
        "    h_mag = h_mag_norm * (-db_limit) + db_limit\n",
        "    h_mag = tsms.core.db_to_lin(h_mag)\n",
        "\n",
        "    return h_mag\n",
        "\n",
        "\n",
        "def map_features(features):\n",
        "    note_number = tf.cast(features['note_number'], dtype=tf.int32)\n",
        "    velocity = tf.cast(features['velocity'], dtype=tf.int32)\n",
        "    instrument_id = tf.cast(features['instrument_id'], dtype=tf.int32)\n",
        "\n",
        "    h_freq = features['h_freq']\n",
        "    h_mag = features['h_mag']\n",
        "\n",
        "    h_freq = tf.io.parse_tensor(h_freq, out_type=tf.string)\n",
        "    h_mag = tf.io.parse_tensor(h_mag, out_type=tf.string)\n",
        "\n",
        "    h_freq = tf.io.parse_tensor(h_freq, out_type=tf.float32)\n",
        "    h_mag = tf.io.parse_tensor(h_mag, out_type=tf.float32)\n",
        "\n",
        "    f0_note = tsms.core.midi_to_hz(tf.cast(note_number, dtype=tf.float32))\n",
        "    harmonics = tsms.core.get_number_harmonics(f0_note, sample_rate=16000)\n",
        "    harmonics = tf.squeeze(harmonics)\n",
        "\n",
        "    h_freq = h_freq[:, :harmonics]\n",
        "    h_mag = h_mag[:, :harmonics]\n",
        "\n",
        "    h_freq = tf.expand_dims(h_freq, axis=0)\n",
        "    h_mag = tf.expand_dims(h_mag, axis=0)\n",
        "\n",
        "    h_freq_norm = normalize_h_freq(h_freq, h_mag, note_number)\n",
        "    h_mag_norm = normalize_h_mag(h_mag)\n",
        "\n",
        "    h_freq_norm = tf.squeeze(h_freq_norm, axis=0)\n",
        "    h_mag_norm = tf.squeeze(h_mag_norm, axis=0)\n",
        "\n",
        "    pad_size = max_harmonics - tf.shape(h_freq_norm)[1]\n",
        "    h_freq_norm = tf.pad(h_freq_norm, paddings=((0, 0), (0, pad_size)))\n",
        "    h_mag_norm = tf.pad(h_mag_norm, paddings=((0, 0), (0, pad_size)))\n",
        "\n",
        "    mask = tf.concat([\n",
        "        tf.ones(shape=(tf.shape(h_freq_norm)[0], harmonics)),\n",
        "        tf.zeros(shape=(tf.shape(h_freq_norm)[0], max_harmonics - harmonics)),\n",
        "    ], axis=1)\n",
        "\n",
        "    inputs = {\n",
        "        'note_number': note_number,\n",
        "        'velocity': velocity,\n",
        "        'instrument_id': instrument_id,\n",
        "        'h_freq_norm': h_freq_norm,\n",
        "        'h_mag_norm': h_mag_norm,\n",
        "        'mask': mask,\n",
        "        'harmonics': harmonics\n",
        "    }\n",
        "\n",
        "    targets = tf.stack([h_freq_norm, h_mag_norm, mask], axis=-1)\n",
        "\n",
        "    return inputs, targets"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7dYOU811Ni4"
      },
      "source": [
        "## Create datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBa055Xy1MIL"
      },
      "source": [
        "batch_size = 8\n",
        "\n",
        "dataset_dir = \"/content/drive/My Drive/nsynth_guitar/dataset/new_data\"\n",
        "\n",
        "train_tfrecord_file = os.path.join(dataset_dir, 'train.tfrecord')\n",
        "valid_tfrecord_file = os.path.join(dataset_dir, 'valid.tfrecord')\n",
        "test_tfrecord_file = os.path.join(dataset_dir, 'test.tfrecord')\n",
        "\n",
        "# Create train dataset\n",
        "train_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=train_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=map_features)\n",
        "\n",
        "train_dataset = train_data_provider.get_batch(\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    repeats=1)\n",
        "\n",
        "# Create valid dataset\n",
        "valid_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=valid_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=map_features)\n",
        "\n",
        "valid_dataset = valid_data_provider.get_batch(\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    repeats=1)\n",
        "\n",
        "# Create test dataset\n",
        "test_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=test_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=map_features)\n",
        "\n",
        "test_dataset = test_data_provider.get_batch(\n",
        "    1,\n",
        "    shuffle=True,\n",
        "    repeats=1)\n",
        "\n",
        "\n",
        "train_dataset = train_dataset.apply(\n",
        "    tf.data.experimental.assert_cardinality(10542))\n",
        "valid_dataset = valid_dataset.apply(\n",
        "    tf.data.experimental.assert_cardinality(2906))\n",
        "test_dataset = test_dataset.apply(\n",
        "    tf.data.experimental.assert_cardinality(1588))"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF-VT1jTD6S7"
      },
      "source": [
        "# train_count = 0\n",
        "# for step, batch in enumerate(train_dataset):\n",
        "#     train_count += 1\n",
        "\n",
        "# print(\"train: \", train_count)\n",
        "\n",
        "# valid_count = 0\n",
        "# for step, batch in enumerate(valid_dataset):\n",
        "#     valid_count += 1\n",
        "\n",
        "# print(\"valid: \", valid_count)\n",
        "\n",
        "# test_count = 0\n",
        "# for step, batch in enumerate(test_dataset):\n",
        "#     test_count += 1\n",
        "\n",
        "# print(\"test: \", test_count)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVxCGOXOY4Ab"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQaueb_AbcOK"
      },
      "source": [
        "def ffn(input_shape, num_layers, hidden_units, output_units, name='ffn'):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Dense(hidden_units, name=name + '_in_dense')(inputs)\n",
        "    x = tf.keras.layers.LayerNormalization(name=name + '_in_ln')(x)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        y = tf.keras.layers.Dense(hidden_units, activation='relu',\n",
        "                                  name=name + '_dense_' + str(i))(x)\n",
        "        x = tf.keras.layers.Add(name=name + '_add_' + str(i))([x, y])\n",
        "        x = tf.keras.layers.LayerNormalization(name=name + '_ln_' + str(i))(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(output_units, name=name + '_out_dense_')(x)\n",
        "    return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "def rnn_sandwich(seq_len, inputs, outputs, num_layers, hidden_units,\n",
        "                 return_sequences=True, name='rnn_sandwich'):\n",
        "    ffn_in = ffn(input_shape=(seq_len, inputs),\n",
        "                 num_layers=num_layers,\n",
        "                 hidden_units=hidden_units,\n",
        "                 output_units=hidden_units,\n",
        "                 name=name + '_fnn_in_')\n",
        "\n",
        "    gru = tf.keras.layers.GRU(hidden_units, return_sequences=return_sequences,\n",
        "                              name=name + '_gru_')\n",
        "\n",
        "    s = (seq_len, hidden_units) if return_sequences else (hidden_units,)\n",
        "    ffn_out = ffn(input_shape=s,\n",
        "                  num_layers=num_layers,\n",
        "                  hidden_units=hidden_units,\n",
        "                  output_units=outputs,\n",
        "                  name=name + '_fnn_out_')\n",
        "\n",
        "    return tf.keras.Sequential([ffn_in, gru, ffn_out])\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, in_ch=128, h_ch=256, z_ch=256, seq_len=1001):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        self.note_embedding = tf.keras.layers.Embedding(\n",
        "            input_dim=(max_note_number - min_note_number + 1),\n",
        "            output_dim=(in_ch - max_harmonics))\n",
        "\n",
        "        self.freq_rnn = rnn_sandwich(\n",
        "            seq_len=seq_len,\n",
        "            inputs=in_ch,\n",
        "            outputs=z_ch // 2,\n",
        "            num_layers=2,\n",
        "            hidden_units=h_ch,\n",
        "            return_sequences=True,\n",
        "            name='freq_rnn')\n",
        "\n",
        "        self.mag_rnn = rnn_sandwich(\n",
        "            seq_len=seq_len,\n",
        "            inputs=in_ch,\n",
        "            outputs=z_ch // 2,\n",
        "            num_layers=2,\n",
        "            hidden_units=h_ch,\n",
        "            return_sequences=True,\n",
        "            name='mag_rnn')\n",
        "\n",
        "        self.downsampler = rnn_sandwich(\n",
        "            seq_len=seq_len,\n",
        "            inputs=z_ch,\n",
        "            outputs=z_ch,\n",
        "            num_layers=2,\n",
        "            hidden_units=z_ch,\n",
        "            return_sequences=False,\n",
        "            name='downsampler')\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        note_index = inputs['note_number'] - min_note_number\n",
        "        e = self.note_embedding(note_index)\n",
        "        e = tf.repeat(e, self.seq_len, axis=1)\n",
        "\n",
        "        freq = tf.concat([inputs['h_freq_norm'], e], axis=-1)\n",
        "        mag = tf.concat([inputs['h_mag_norm'], e], axis=-1)\n",
        "\n",
        "        freq = self.freq_rnn(freq, training=training)\n",
        "        mag = self.mag_rnn(mag, training=training)\n",
        "\n",
        "        x = tf.concat([freq, mag], axis=-1)\n",
        "        z = self.downsampler(x, training=training)\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, in_ch=128, h_ch=64, z_ch=256, seq_len=1001):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        self.upsampler = self.add_weight(\n",
        "            name='upsampler',\n",
        "            shape=(1, z_ch, seq_len),\n",
        "            initializer='ones')\n",
        "\n",
        "        self.rnn = rnn_sandwich(\n",
        "            seq_len=seq_len,\n",
        "            inputs=z_ch,\n",
        "            outputs=h_ch * 2,\n",
        "            num_layers=2,\n",
        "            hidden_units=h_ch,\n",
        "            return_sequences=True,\n",
        "            name='rnn')\n",
        "\n",
        "        self.note_embedding = tf.keras.layers.Embedding(\n",
        "            input_dim=(max_note_number - min_note_number + 1),\n",
        "            output_dim=h_ch)\n",
        "\n",
        "        self.freq_rnn = rnn_sandwich(\n",
        "            seq_len=seq_len,\n",
        "            inputs=h_ch * 2,\n",
        "            outputs=max_harmonics,\n",
        "            num_layers=2,\n",
        "            hidden_units=h_ch * 2,\n",
        "            return_sequences=True,\n",
        "            name='freq_rnn')\n",
        "\n",
        "        self.mag_rnn = rnn_sandwich(\n",
        "            seq_len=seq_len,\n",
        "            inputs=h_ch * 2,\n",
        "            outputs=max_harmonics,\n",
        "            num_layers=2,\n",
        "            hidden_units=h_ch * 2,\n",
        "            return_sequences=True,\n",
        "            name='mag_rnn')\n",
        "\n",
        "    def call(self, inputs, z, training=None, mask=None):\n",
        "        z = tf.expand_dims(z, axis=-1)\n",
        "        x = tf.math.multiply(z, self.upsampler)\n",
        "        x = tf.transpose(x, perm=(0, 2, 1))\n",
        "\n",
        "        x = self.rnn(x, training=training)\n",
        "        x_freq, x_mag = tf.split(x, 2, axis=-1)\n",
        "\n",
        "        note_index = inputs['note_number'] - min_note_number\n",
        "        e = self.note_embedding(note_index)\n",
        "        e = tf.repeat(e, self.seq_len, axis=1)\n",
        "\n",
        "        x_freq = tf.concat([x_freq, e], axis=-1)\n",
        "        x_mag = tf.concat([x_mag, e], axis=-1)\n",
        "\n",
        "        h_freq_norm = self.freq_rnn(x_freq, training=training)\n",
        "        h_mag_norm = self.mag_rnn(x_mag, training=training)\n",
        "\n",
        "        h_freq_norm *= inputs['mask']\n",
        "        h_mag_norm *= inputs['mask']\n",
        "\n",
        "        y = tf.stack([h_freq_norm, h_mag_norm], axis=-1)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "class AutoEncoder(tf.keras.Model):\n",
        "    def __init__(self, in_ch=128, h_ch=64, z_ch=256, seq_len=1001):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(in_ch, h_ch, z_ch, seq_len)\n",
        "        self.decoder = Decoder(in_ch, h_ch, z_ch, seq_len)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        z = self.encoder(inputs)\n",
        "        y = self.decoder(inputs, z)\n",
        "\n",
        "        return y"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXqny89zuZMs"
      },
      "source": [
        "class FreqLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self,\n",
        "                 reduction=tf.keras.losses.Reduction.AUTO,\n",
        "                 name='freq_loss'):\n",
        "        super(FreqLoss, self).__init__(\n",
        "            reduction=reduction,\n",
        "            name=name)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        h_freq_norm_true, h_mag_norm_true, mask = tf.unstack(y_true, axis=-1)\n",
        "        h_freq_norm_pred, h_mag_norm_pred = tf.unstack(y_pred, axis=-1)\n",
        "\n",
        "        num_elems = tf.math.reduce_sum(mask)\n",
        "\n",
        "        h_mag = denormalize_h_mag(h_mag_norm_true)\n",
        "        h_mag_mean = tf.math.reduce_sum(h_mag)\n",
        "        \n",
        "        freq_loss = tf.math.reduce_sum(\n",
        "            h_mag * tf.square(h_freq_norm_true - h_freq_norm_pred))\n",
        "        freq_loss = freq_loss / h_mag_mean\n",
        "\n",
        "        return freq_loss\n",
        "\n",
        "\n",
        "class MagLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self,\n",
        "                 reduction=tf.keras.losses.Reduction.AUTO,\n",
        "                 name='mag_loss'):\n",
        "        super(MagLoss, self).__init__(\n",
        "            reduction=reduction,\n",
        "            name=name)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        h_freq_norm_true, h_mag_norm_true, mask = tf.unstack(y_true, axis=-1)\n",
        "        h_freq_norm_pred, h_mag_norm_pred = tf.unstack(y_pred, axis=-1)\n",
        "\n",
        "        num_elems = tf.math.reduce_sum(mask)\n",
        "\n",
        "        mag_loss = tf.math.reduce_sum(\n",
        "            tf.square(h_mag_norm_true - h_mag_norm_pred)) / num_elems\n",
        "\n",
        "        return mag_loss"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTiP6aA82Uay"
      },
      "source": [
        "# Create and compile mapping model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26aSTwuy2ZKy"
      },
      "source": [
        "auto_encoder = AutoEncoder()\n",
        "freq_loss = FreqLoss()\n",
        "mag_loss = MagLoss()\n",
        "\n",
        "auto_encoder.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=lambda yt, yp: freq_loss(yt, yp) + mag_loss(yt, yp),\n",
        "    metrics=[freq_loss, mag_loss],\n",
        "    run_eagerly=False)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zceUmkJI35zb"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoczioW23-Da"
      },
      "source": [
        "x_true, y_true = next(iter(train_dataset))\n",
        "y_pred = auto_encoder(x_true)\n",
        "# loss_value = harmonic_loss(y_true, y_pred)\n",
        "\n",
        "auto_encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SunnK0BY2utQ"
      },
      "source": [
        "# Load model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi46si8f2bOi"
      },
      "source": [
        "checkpoint_file = os.path.join(checkpoint_dir, 'cp.ckpt')\n",
        "\n",
        "if os.path.isdir(checkpoint_dir) and os.listdir(checkpoint_dir):\n",
        "    auto_encoder.load_weights(checkpoint_file)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkCyoCxp3l7r"
      },
      "source": [
        "## Create training callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23w7DNkh2ytf"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_file,\n",
        "    save_weights_only=True,\n",
        "    verbose=0,\n",
        "    save_freq='epoch')\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 10:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * 0.9\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCkWXZD-5XsD"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl4D5c_u5a1x"
      },
      "source": [
        "epochs = 50\n",
        "steps_per_epoch = 100\n",
        "validation_steps = 10\n",
        "\n",
        "auto_encoder.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_dataset,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[early_stop, lr_scheduler, checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNyLeJcN6wS8"
      },
      "source": [
        "## Evaluate model on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX4SXagL6vwB"
      },
      "source": [
        "auto_encoder.evaluate(test_dataset, steps=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5yqSI3e8i4U"
      },
      "source": [
        "### Get Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Te94ZhJK9Gq"
      },
      "source": [
        "iterator = iter(test_dataset)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A2hgXwivy8I"
      },
      "source": [
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def reconstruct_audio(h_freq, h_mag):\n",
        "    h_phase = tsms.core.generate_phase(h_freq, sample_rate, frame_step)\n",
        "    return tsms.core.harmonic_synthesis(\n",
        "        h_freq, h_mag, h_phase, sample_rate, frame_step)\n",
        "\n",
        "\n",
        "x_true, y_true = next(iterator)\n",
        "y_pred = auto_encoder(x_true)\n",
        "\n",
        "note_number = x_true['note_number']\n",
        "harmonics = tf.squeeze(x_true['harmonics'])\n",
        "\n",
        "h_freq_norm_true, h_mag_norm_true, mask = tf.unstack(y_true, axis=-1)\n",
        "h_freq_norm_pred, h_mag_norm_pred = tf.unstack(y_pred, axis=-1)\n",
        "\n",
        "h_freq_true = denormalize_h_freq(h_freq_norm_true, note_number)\n",
        "h_freq_pred = denormalize_h_freq(h_freq_norm_pred, note_number)\n",
        "\n",
        "h_mag_true = denormalize_h_mag(h_mag_norm_true)\n",
        "h_mag_pred = denormalize_h_mag(h_mag_norm_pred)\n",
        "\n",
        "h_freq_true = h_freq_true[:, :, :harmonics]\n",
        "h_freq_pred = h_freq_pred[:, :, :harmonics]\n",
        "\n",
        "h_mag_true = h_mag_true[:, :, :harmonics]\n",
        "h_mag_pred = h_mag_pred[:, :, :harmonics]\n",
        "\n",
        "audio_true = reconstruct_audio(h_freq_true, h_mag_true)\n",
        "audio_pred = reconstruct_audio(h_freq_pred, h_mag_pred)\n",
        "\n",
        "audio_true = np.squeeze(audio_true.numpy())\n",
        "audio_pred = np.squeeze(audio_pred.numpy())\n",
        "\n",
        "sf.write('/content/audio_true.wav', audio_true, sample_rate)\n",
        "sf.write('/content/audio_pred.wav', audio_pred, sample_rate)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.squeeze(h_freq_true))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.squeeze(h_mag_true))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.squeeze(h_freq_pred))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.squeeze(h_mag_pred))\n",
        "\n",
        "\n",
        "print('\\True\\n')\n",
        "IPython.display.display(IPython.display.Audio('/content/audio_true.wav'))\n",
        "print('\\Pred\\n')\n",
        "IPython.display.display(IPython.display.Audio('/content/audio_pred.wav'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}